{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c00630-ddf7-4ad0-b76a-326b4850156e",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #f9fafb, #eef2f7); padding:28px; border-radius:14px; font-family:'Segoe UI', Roboto, Arial, sans-serif; color:#1f2937; line-height:1.65; border:1px solid #d1d5db; box-shadow:0 6px 18px rgba(0,0,0,0.08); max-width:980px;\">\n",
    "\n",
    "  <h1 style=\"margin:0 0 10px 0; font-size:28px; color:#111827; font-weight:700; text-shadow:0 1px 2px rgba(0,0,0,0.08);\">\n",
    "    DA5401 A7: Multi-Class Model Selection using ROC and Precision-Recall Curves\n",
    "  </h1>\n",
    "\n",
    "  <p style=\"margin:4px 0 18px 0; color:#4b5563; font-size:15px;\">\n",
    "    <strong>Student Name:</strong> Ashish Rajhans Meshram &nbsp;&nbsp;|&nbsp;&nbsp;\n",
    "    <strong>Roll No:</strong> DA25M016\n",
    "  </p>\n",
    "\n",
    "  <p style=\"margin:0 0 22px 0; font-size:15.5px; color:#374151;\">\n",
    "    This notebook explores <strong>multi-class model evaluation and selection</strong> using the \n",
    "    <strong>UCI Landsat Satellite Dataset</strong>.  \n",
    "    You will train diverse classifiers and compare their performances using \n",
    "    <strong>Receiver Operating Characteristic (ROC)</strong> and \n",
    "    <strong>Precision–Recall Curve (PRC)</strong> analysis.  \n",
    "    The emphasis is on interpreting model behavior across thresholds—not just overall accuracy.\n",
    "  </p>\n",
    "\n",
    "  <hr style=\"border:none; border-top:1px solid #d1d5db; margin:20px 0;\">\n",
    "\n",
    "  <h2 style=\"font-size:17px; color:#1e3a8a; margin:0 0 10px 0; padding-bottom:6px; border-bottom:2px solid #93c5fd;\">\n",
    "     Problem Statement\n",
    "  </h2>\n",
    "\n",
    "  <p style=\"margin:10px 0 14px 0; color:#374151;\">\n",
    "    As a machine learning scientist, you are tasked with classifying <strong>land cover types</strong> \n",
    "    from satellite images. The <strong>Landsat Satellite Dataset</strong> is a 6-class problem with overlapping boundaries and high-dimensional features.  \n",
    "    Your goal is to perform model selection through a comprehensive threshold-based evaluation using ROC and PRC metrics under a \n",
    "    <strong>One-vs-Rest (OvR)</strong> framework.\n",
    "  </p>\n",
    "\n",
    "  <p style=\"margin:0 0 18px 0; color:#6b7280; font-size:14.5px;\">\n",
    "    <strong>Dataset:</strong> UCI Statlog (Landsat Satellite) Dataset  \n",
    "    <em>Source:</em> <a href=\"https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)\" target=\"_blank\" style=\"color:#2563eb; text-decoration:none;\">UCI Machine Learning Repository</a>\n",
    "  </p>\n",
    "\n",
    "  <hr style=\"border:none; border-top:1px solid #d1d5db; margin:20px 0;\">\n",
    "\n",
    "  <h2 style=\"font-size:17px; color:#1e3a8a; margin:0 0 10px 0; padding-bottom:6px; border-bottom:2px solid #93c5fd;\">\n",
    "     Notebook Outline\n",
    "  </h2>\n",
    "\n",
    "  <ol style=\"color:#111827; padding-left:20px; margin-top:12px; font-size:15px;\">\n",
    "    <li style=\"margin-bottom:16px; font-weight:600;\">\n",
    "      Part A: Data Preparation and Baseline [5 points]\n",
    "      <ul style=\"color:#4b5563; margin-top:8px; padding-left:18px; font-weight:400;\">\n",
    "        <li>Load and standardize the Landsat dataset.</li>\n",
    "        <li>Split into <strong>training</strong> and <strong>testing</strong> sets with stratified sampling.</li>\n",
    "        <li>Train six classifiers: KNN, Decision Tree, Dummy (Prior), Logistic Regression, GaussianNB, and SVC (with probability=True).</li>\n",
    "        <li>Compute <strong>Accuracy</strong> and <strong>Weighted F1-Score</strong> to establish baselines.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "\n",
    " <li style=\"margin-bottom:16px; font-weight:600;\">\n",
    "   Part B: ROC Curve Analysis [20 points]\n",
    "      <ul style=\"color:#4b5563; margin-top:8px; padding-left:18px; font-weight:400;\">\n",
    "        <li>Explain the <strong>One-vs-Rest (OvR)</strong> ROC strategy for multi-class evaluation.</li>\n",
    "        <li>Plot macro-averaged ROC curves for all models in one chart.</li>\n",
    "        <li>Compute and compare <strong>Area Under Curve (AUC)</strong> values.</li>\n",
    "        <li>Interpret models with <strong>AUC &lt; 0.5</strong> and discuss why this occurs.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "\n",
    " <li style=\"margin-bottom:16px; font-weight:600;\">\n",
    "    Part C: Precision–Recall Curve (PRC) Analysis [20 points]\n",
    "      <ul style=\"color:#4b5563; margin-top:8px; padding-left:18px; font-weight:400;\">\n",
    "        <li>Discuss why PRC is often more insightful for imbalanced datasets.</li>\n",
    "        <li>Plot macro-averaged PRC curves and compute <strong>Average Precision (AP)</strong>.</li>\n",
    "        <li>Analyze the PRC behavior of the worst-performing model and discuss rapid precision drops.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "\n",
    " <li style=\"margin-bottom:16px; font-weight:600;\">\n",
    "      Part D: Final Recommendation [5 points]\n",
    "      <ul style=\"color:#4b5563; margin-top:8px; padding-left:18px; font-weight:400;\">\n",
    "        <li>Compare rankings from <strong>F1-score</strong>, <strong>ROC-AUC</strong>, and <strong>PRC-AP</strong>.</li>\n",
    "        <li>Discuss metric trade-offs and alignment between ranking orders.</li>\n",
    "        <li>Recommend the <strong>most reliable model</strong> for deployment with justification.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "\n",
    " <li style=\"margin-bottom:6px; font-weight:600;\">\n",
    "      Bonus Task [+5 points]\n",
    "      <ul style=\"color:#4b5563; margin-top:8px; padding-left:18px; font-weight:400;\">\n",
    "        <li>Experiment with <strong>RandomForest</strong> and <strong>XGBoost</strong> classifiers.</li>\n",
    "        <li>Include one intentionally poor model (AUC &lt; 0.5) to demonstrate negative learning behavior.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ol>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b779d5-cc3e-4ec7-85eb-68f54fbd7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
    "    classification_report, confusion_matrix, accuracy_score\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Model classes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "sns.set_palette(\"colorblind\")\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184833ff-61ce-401b-ac19-3791c1162a4d",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #2b3a4a;\n",
    "    padding: 20px 25px;\n",
    "    margin: 30px 0 20px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #5a9bd5;\n",
    "    box-shadow: 0 4px 10px rgba(0,0,0,0.25);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h2 style=\"\n",
    "        font-size: 1.7em;\n",
    "        font-weight: 600;\n",
    "        color: #ffffff;\n",
    "        margin: 0;\n",
    "        text-shadow: 1px 1px 3px rgba(0,0,0,0.3);\n",
    "    \">\n",
    "         Part A: Data Preparation and Baseline Evaluation\n",
    "    </h2>\n",
    "    <p style=\"\n",
    "        color: #b0bec5;\n",
    "        margin: 8px 0 12px 0;\n",
    "        font-size: 1em;\n",
    "        font-weight: 300;\n",
    "    \">\n",
    "        Load, preprocess, and evaluate the baseline performance of multiple classifiers on the Landsat Satellite Dataset before deeper ROC/PRC analysis.\n",
    "    </p>\n",
    "\n",
    "  <ul style=\"color:#d1d5db; margin:0; padding-left:22px; line-height:1.6;\">\n",
    "        <li>Load the <strong>UCI Landsat Satellite Dataset</strong> and perform data cleaning if necessary.</li>\n",
    "        <li>Standardize all numerical features using <strong>StandardScaler</strong> to ensure fair model comparison.</li>\n",
    "        <li>Split the dataset into <strong>training</strong> and <strong>testing</strong> sets using stratified sampling to maintain class balance.</li>\n",
    "        <li>Train six baseline models:\n",
    "            <ul style=\"margin-top:6px; color:#b0bec5;\">\n",
    "                <li>K-Nearest Neighbors (KNN)</li>\n",
    "                <li>Decision Tree Classifier</li>\n",
    "                <li>Dummy Classifier (Prior)</li>\n",
    "                <li>Logistic Regression</li>\n",
    "                <li>Gaussian Naive Bayes</li>\n",
    "                <li>Support Vector Classifier (SVC) with <code>probability=True</code></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Compute and record <strong>Overall Accuracy</strong> and <strong>Weighted F1-Score</strong> for all models to establish baseline rankings.</li>\n",
    "        <li>Observe which models perform poorly and are potential candidates for AUC &lt; 0.5 behavior in later analysis.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13deda7-ba27-40c8-ba4c-45f7a7422252",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h3 style=\"\n",
    "        font-size: 1.3em;\n",
    "        font-weight: 600;\n",
    "        color: #263238;\n",
    "        margin: 0 0 8px 0;\n",
    "    \">\n",
    "        1. Load and Prepare Dataset\n",
    "    </h3>\n",
    "    <p style=\"\n",
    "        color: #546e7a;\n",
    "        margin: 0 0 10px 0;\n",
    "        font-size: 0.95em;\n",
    "        font-weight: 400;\n",
    "        line-height: 1.6;\n",
    "    \">\n",
    "        This section handles the initial preparation of the <b>UCI Landsat Satellite Dataset</b>.\n",
    "        Tasks include loading the dataset, cleaning column names, verifying data integrity, \n",
    "        and splitting the target variable from the feature matrix for subsequent preprocessing and modeling.\n",
    "    </p>\n",
    "    <ul style=\"\n",
    "        color: #546e7a;\n",
    "        font-size: 0.9em;\n",
    "        font-weight: 400;\n",
    "        padding-left: 22px;\n",
    "        margin: 0;\n",
    "        list-style-type: square;\n",
    "    \">\n",
    "        <li style=\"padding-bottom: 5px;\">\n",
    "            Load the Landsat dataset (either from <code>arff</code> or <code>csv</code> format).\n",
    "        </li>\n",
    "        <li style=\"padding-bottom: 5px;\">\n",
    "            Inspect dataset shape, null counts, and sample rows to ensure consistent structure.\n",
    "        </li>\n",
    "        <li>\n",
    "            Separate features (<b>X</b>) and target (<b>y</b>) variables for further analysis.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb0d7b0-e8eb-441e-9c2b-4f8df3f911c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4435, 37)\n",
      "Test data shape: (2000, 37)\n"
     ]
    }
   ],
   "source": [
    "train_url = \"data/sat.trn\"\n",
    "test_url = \"data/sat.tst\"\n",
    "\n",
    "# Column names: 36 features + 1 class label\n",
    "column_names = [f'feature_{i}' for i in range(1, 37)] + ['class']\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv(train_url, sep=' ', names=column_names, header=None)\n",
    "test_data = pd.read_csv(test_url, sep=' ', names=column_names, header=None)\n",
    "\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0175733-6cf8-423e-afc6-60e33abd44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of training data:\n",
      "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
      "0         92        115        120         94         84        102   \n",
      "1         84        102        106         79         84        102   \n",
      "2         84        102        102         83         80        102   \n",
      "3         80        102        102         79         84         94   \n",
      "4         84         94        102         79         80         94   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  ...  feature_28  feature_29  \\\n",
      "0        106         79         84         102  ...         104          88   \n",
      "1        102         83         80         102  ...         100          84   \n",
      "2        102         79         84          94  ...          87          84   \n",
      "3        102         79         80          94  ...          79          84   \n",
      "4         98         76         80         102  ...          79          84   \n",
      "\n",
      "   feature_30  feature_31  feature_32  feature_33  feature_34  feature_35  \\\n",
      "0         121         128         100          84         107         113   \n",
      "1         107         113          87          84          99         104   \n",
      "2          99         104          79          84          99         104   \n",
      "3          99         104          79          84         103         104   \n",
      "4         103         104          79          79         107         109   \n",
      "\n",
      "   feature_36  class  \n",
      "0          87      3  \n",
      "1          79      3  \n",
      "2          79      3  \n",
      "3          79      3  \n",
      "4          87      3  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4435 entries, 0 to 4434\n",
      "Data columns (total 37 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   feature_1   4435 non-null   int64\n",
      " 1   feature_2   4435 non-null   int64\n",
      " 2   feature_3   4435 non-null   int64\n",
      " 3   feature_4   4435 non-null   int64\n",
      " 4   feature_5   4435 non-null   int64\n",
      " 5   feature_6   4435 non-null   int64\n",
      " 6   feature_7   4435 non-null   int64\n",
      " 7   feature_8   4435 non-null   int64\n",
      " 8   feature_9   4435 non-null   int64\n",
      " 9   feature_10  4435 non-null   int64\n",
      " 10  feature_11  4435 non-null   int64\n",
      " 11  feature_12  4435 non-null   int64\n",
      " 12  feature_13  4435 non-null   int64\n",
      " 13  feature_14  4435 non-null   int64\n",
      " 14  feature_15  4435 non-null   int64\n",
      " 15  feature_16  4435 non-null   int64\n",
      " 16  feature_17  4435 non-null   int64\n",
      " 17  feature_18  4435 non-null   int64\n",
      " 18  feature_19  4435 non-null   int64\n",
      " 19  feature_20  4435 non-null   int64\n",
      " 20  feature_21  4435 non-null   int64\n",
      " 21  feature_22  4435 non-null   int64\n",
      " 22  feature_23  4435 non-null   int64\n",
      " 23  feature_24  4435 non-null   int64\n",
      " 24  feature_25  4435 non-null   int64\n",
      " 25  feature_26  4435 non-null   int64\n",
      " 26  feature_27  4435 non-null   int64\n",
      " 27  feature_28  4435 non-null   int64\n",
      " 28  feature_29  4435 non-null   int64\n",
      " 29  feature_30  4435 non-null   int64\n",
      " 30  feature_31  4435 non-null   int64\n",
      " 31  feature_32  4435 non-null   int64\n",
      " 32  feature_33  4435 non-null   int64\n",
      " 33  feature_34  4435 non-null   int64\n",
      " 34  feature_35  4435 non-null   int64\n",
      " 35  feature_36  4435 non-null   int64\n",
      " 36  class       4435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print(\"First few rows of training data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "\n",
    "print(\"\\nDataset Information:\")\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589e0caa-5463-4857-b3f3-fa471f6e2c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution in Training Data:\n",
      "class\n",
      "1    1072\n",
      "2     479\n",
      "3     961\n",
      "4     415\n",
      "5     470\n",
      "7    1038\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Distribution in Test Data:\n",
      "class\n",
      "1    461\n",
      "2    224\n",
      "3    397\n",
      "4    211\n",
      "5    237\n",
      "7    470\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: The dataset shows class imbalance, which will affect model performance.\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"\\nClass Distribution in Training Data:\")\n",
    "print(train_data['class'].value_counts().sort_index())\n",
    "print(\"\\nClass Distribution in Test Data:\")\n",
    "print(test_data['class'].value_counts().sort_index())\n",
    "\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "train_data['class'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Training Data Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class Label', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "test_data['class'].value_counts().sort_index().plot(kind='bar', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Test Data Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class Label', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: The dataset shows class imbalance, which will affect model performance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d31e3b-1e31-48db-bd8f-4889d9cecb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in training data:\n",
      "0\n",
      "\n",
      "Missing values in test data:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(train_data.isnull().sum().sum())\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6129ac-42e3-4e52-9a68-f41de000a18d",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        2. Standardize Features\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Standardize numeric features using <b>StandardScaler</b> to ensure all models receive inputs on comparable scales. \n",
    "        This step is crucial for distance-based models like KNN and SVM.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Apply <code>StandardScaler()</code> to transform all features to zero mean and unit variance.</li>\n",
    "        <li>Retain target variable separately to avoid data leakage.</li>\n",
    "        <li>Store transformed data as <code>X_scaled</code> for model input.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fcd896-13d1-45ab-b77f-3101c0ac13d4",
   "metadata": {},
   "source": [
    "#### Standard Scaling \n",
    "This is crucial for distance-based and gradient-based algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215b3936-9030-4d2f-b3cb-8113e6d1bc91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m scaler = StandardScaler()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train_scaled = scaler.fit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[32m      3\u001b[39m X_test_scaled = scaler.transform(X_test)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFeature Standardization Complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature Standardization Complete!\")\n",
    "print(f\"\\nOriginal feature statistics (first feature):\")\n",
    "print(f\"  Mean: {X_train[:, 0].mean():.4f}, Std: {X_train[:, 0].std():.4f}\")\n",
    "print(f\"\\nStandardized feature statistics (first feature):\")\n",
    "print(f\"  Mean: {X_train_scaled[:, 0].mean():.4f}, Std: {X_train_scaled[:, 0].std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9543087-c9d6-4f7a-9885-63b9d13f6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique classes\n",
    "classes = np.unique(y_train)\n",
    "n_classes = len(classes)\n",
    "\n",
    "print(f\"\\nNumber of classes: {n_classes}\")\n",
    "print(f\"Class labels: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def1ed7-3144-4d82-b9d4-502a94be95a8",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        3. Train–Test Split\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Split the dataset into <b>training</b> and <b>testing</b> subsets using a stratified approach to preserve class balance across splits.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Use <code>train_test_split()</code> with <b>stratify=y</b> and an 80–20 split ratio.</li>\n",
    "        <li>Store outputs as <code>X_train</code>, <code>X_test</code>, <code>y_train</code>, <code>y_test</code>.</li>\n",
    "        <li>Ensure reproducibility using a fixed <code>random_state</code>.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33760ad0-7333-4b41-8292-320701ad4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = train_data.drop('class', axis=1).values\n",
    "y_train = train_data['class'].values\n",
    "\n",
    "X_test = test_data.drop('class', axis=1).values\n",
    "y_test = test_data['class'].values\n",
    "\n",
    "print(f\"Training set: X_train shape = {X_train.shape}, y_train shape = {y_train.shape}\")\n",
    "print(f\"Test set: X_test shape = {X_test.shape}, y_test shape = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929ea6d-a810-4b66-94c2-303077a8b893",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        4. Train Baseline Models\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Train multiple baseline classifiers to establish performance benchmarks before ROC and PRC analysis.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Models: KNN, Decision Tree, Dummy (Prior), Logistic Regression, GaussianNB, and SVC (<code>probability=True</code>).</li>\n",
    "        <li>Train each classifier on <code>X_train</code> and <code>y_train</code>.</li>\n",
    "        <li>Evaluate using <b>Accuracy</b> and <b>Weighted F1-score</b>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0edb33e-6e74-43f3-88bb-d6dcb79a89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    \n",
    "    'Decision Tree': DecisionTreeClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_depth=10\n",
    "    ),\n",
    "    \n",
    "    'Dummy Classifier (Prior)': DummyClassifier(\n",
    "        strategy='prior',\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    \n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_iter=1000,\n",
    "        multi_class='ovr',\n",
    "        solver='lbfgs'\n",
    "    ),\n",
    "    \n",
    "    'Naive Bayes (Gaussian)': GaussianNB(),\n",
    "    \n",
    "    'Support Vector Machine': SVC(\n",
    "        random_state=RANDOM_STATE,\n",
    "        probability=True,  # ⚠️ CRITICAL: Required for predict_proba in ROC/PRC\n",
    "        kernel='rbf',\n",
    "        gamma='scale'\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SIX MODELS DEFINED\")\n",
    "print(\"=\"*70)\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    print(f\"{i}. {name}\")\n",
    "    if name == 'Support Vector Machine':\n",
    "        print(f\" probability=True (required for ROC/PRC analysis)\")\n",
    "    elif name == 'Dummy Classifier (Prior)':\n",
    "        print(f\" strategy='prior' (as specified)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c96af4-7cda-4935-98c1-6f2f971ef686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store trained models and predictions\n",
    "trained_models = {}\n",
    "predictions = {}\n",
    "probabilities = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING ALL MODELS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNote: Training on X_train_scaled, y_train\")\n",
    "print(\"Testing on X_test_scaled, y_test\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training: {name}...\")\n",
    "    \n",
    "    # Train the model on training data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Get probability estimates (required for ROC and PRC)\n",
    "    # predict_proba returns probabilities for each class\n",
    "    y_prob = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    # Store results\n",
    "    trained_models[name] = model\n",
    "    predictions[name] = y_pred\n",
    "    probabilities[name] = y_prob\n",
    "    \n",
    "    print(f\"   ✓ Model trained successfully\")\n",
    "    print(f\"   • Predictions shape: {y_pred.shape}\")\n",
    "    print(f\"   • Probabilities shape: {y_prob.shape}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ALL MODELS TRAINED SUCCESSFULLY! ✓\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67795289-843e-48dc-b2e1-3300fa671f0e",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        5. Evaluate Baseline Performance\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Compare all baseline models using <b>Accuracy</b> and <b>Weighted F1-Score</b> to identify strong and weak classifiers.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Compute metrics using <code>classification_report()</code> or <code>cross_val_score()</code>.</li>\n",
    "        <li>Summarize results in a comparative table or bar chart.</li>\n",
    "        <li>Identify underperformers (potential AUC &lt; 0.5 candidates).</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6d4c9-28d5-4bbc-80f1-e34aa4cc07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline metrics for all models\n",
    "baseline_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE EVALUATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nCalculating Overall Accuracy and Weighted F1-Score for all models...\\n\")\n",
    "\n",
    "for name in models.keys():\n",
    "    y_pred = predictions[name]\n",
    "    \n",
    "    # Calculate Overall Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate Weighted F1-Score\n",
    "    # 'weighted' accounts for class imbalance by computing F1 for each class\n",
    "    # and averaging them weighted by support (number of true instances)\n",
    "    weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    baseline_results.append({\n",
    "        'Model': name,\n",
    "        'Overall Accuracy': accuracy,\n",
    "        'Weighted F1-Score': weighted_f1\n",
    "    })\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "\n",
    "# Sort by Overall Accuracy (descending)\n",
    "baseline_df = baseline_df.sort_values('Overall Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(baseline_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f5a40-53c3-42de-9768-9033f0f49920",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #fff8f1;\n",
    "    padding: 24px 26px;\n",
    "    margin: 28px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #fb8c00;\n",
    "    box-shadow: 0 6px 16px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "\n",
    " <h2 style=\"\n",
    "        font-size: 1.6em;\n",
    "        font-weight: 600;\n",
    "        color: #e65100;\n",
    "        margin: 0 0 14px 0;\n",
    "        text-shadow: 0 1px 2px rgba(255,255,255,0.6);\n",
    "    \">\n",
    "         Model Performance Analysis\n",
    "    </h2>\n",
    "\n",
    " <p style=\"\n",
    "        color: #5d4037;\n",
    "        margin: 0 0 14px 0;\n",
    "        font-size: 0.95em;\n",
    "        line-height: 1.6;\n",
    "    \">\n",
    "        After calculating the <b>Overall Accuracy</b> and <b>Weighted F1-Score</b> for all classifiers, \n",
    "        we analyze their comparative performance and derive key insights from model behavior.\n",
    "    </p>\n",
    "\n",
    " <table style=\"\n",
    "        width: 100%;\n",
    "        border-collapse: collapse;\n",
    "        margin: 14px 0 16px 0;\n",
    "        font-size: 0.92em;\n",
    "        color: #4e342e;\n",
    "        background-color: #fff;\n",
    "        border: 1px solid #ffe0b2;\n",
    "        border-radius: 6px;\n",
    "        overflow: hidden;\n",
    "    \">\n",
    "        <thead style=\"background-color: #ffe0b2; color: #3e2723; text-align: left;\">\n",
    "            <tr>\n",
    "                <th style=\"padding: 10px 12px;\">Model</th>\n",
    "                <th style=\"padding: 10px 12px;\">Overall Accuracy</th>\n",
    "                <th style=\"padding: 10px 12px;\">Weighted F1-Score</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr><td style=\"padding: 8px 12px;\"><b>K-Nearest Neighbors</b></td><td>0.9045</td><td>0.9037</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\"><b>Support Vector Machine</b></td><td>0.8955</td><td>0.8925</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\"><b>Decision Tree</b></td><td>0.8565</td><td>0.8558</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\"><b>Logistic Regression</b></td><td>0.8210</td><td>0.7935</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\"><b>Naive Bayes (Gaussian)</b></td><td>0.7965</td><td>0.8036</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\"><b>Dummy Classifier (Prior)</b></td><td>0.2305</td><td>0.0864</td></tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    " <h3 style=\"color:#e65100; margin-top:18px; font-size:1.2em; font-weight:600;\">🔍 Observations</h3>\n",
    "    <ul style=\"color:#5d4037; font-size:0.92em; padding-left:22px; line-height:1.6;\">\n",
    "        <li><b>Top Performers:</b> KNN achieves the <b>highest accuracy (90.45%)</b> and <b>best F1-score (0.9037)</b>, followed closely by SVM.</li>\n",
    "        <li><b>Moderate Performers:</b> Decision Tree shows solid results but overfits slightly; Logistic Regression performs decently on linear patterns.</li>\n",
    "        <li><b>Lower Performers:</b> Naive Bayes struggles due to independence assumptions; Dummy Classifier confirms significant improvement of all other models.</li>\n",
    "    </ul>\n",
    "\n",
    "  <div style=\"\n",
    "        margin-top: 18px;\n",
    "        padding: 14px 16px;\n",
    "        background-color: #ffe0b2;\n",
    "        border-left: 4px solid #fb8c00;\n",
    "        border-radius: 6px;\n",
    "        color: #3e2723;\n",
    "        font-size: 0.95em;\n",
    "        line-height: 1.6;\n",
    "    \">\n",
    "        <b>Conclusion:</b>  \n",
    "        <ul style=\"margin:8px 0 0 16px;\">\n",
    "            <li><b>KNN</b> and <b>SVM</b> are the most effective classifiers for this dataset, balancing accuracy and generalization.</li>\n",
    "            <li><b>Naive Bayes</b> and <b>Dummy Classifier</b> underperform, confirming that they fail to capture complex spatial–spectral dependencies.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7048c-c264-4b34-b4b7-0ca35480335b",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #2b3a4a;\n",
    "    padding: 20px 25px;\n",
    "    margin: 30px 0 20px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #5a9bd5;\n",
    "    box-shadow: 0 4px 10px rgba(0,0,0,0.25);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h2 style=\"\n",
    "        font-size: 1.7em;\n",
    "        font-weight: 600;\n",
    "        color: #ffffff;\n",
    "        margin: 0;\n",
    "        text-shadow: 1px 1px 3px rgba(0,0,0,0.3);\n",
    "    \">\n",
    "         Part B: ROC Analysis for Model Selection\n",
    "    </h2>\n",
    "    <p style=\"\n",
    "        color: #b0bec5;\n",
    "        margin: 8px 0 12px 0;\n",
    "        font-size: 1em;\n",
    "        font-weight: 300;\n",
    "    \">\n",
    "        Implement and interpret <strong>Receiver Operating Characteristic (ROC)</strong> analysis under a <strong>One-vs-Rest (OvR)</strong> framework\n",
    "        to assess how well each classifier discriminates among multiple classes across different thresholds.\n",
    "    </p>\n",
    "\n",
    " <ul style=\"color:#d1d5db; margin:0; padding-left:22px; line-height:1.6;\">\n",
    "      <li>Explain the concept of <strong>multi-class ROC using the One-vs-Rest (OvR)</strong> approach — treating each class as positive vs. the rest.</li>\n",
    "        <li>Use the predicted probabilities (<code>predict_proba()</code>) from each model to compute <strong>False Positive Rate (FPR)</strong> and <strong>True Positive Rate (TPR)</strong> per class.</li>\n",
    "        <li>Aggregate per-class curves to produce <strong>Macro-averaged ROC curves</strong> that summarize model discrimination ability across all six classes.</li>\n",
    "        <li>Plot all ROC curves together with a diagonal random baseline for comparison.</li>\n",
    "        <li>Compute and report <strong>Area Under the Curve (AUC)</strong> values for each model:\n",
    "            <ul style=\"margin-top:6px; color:#b0bec5;\">\n",
    "                <li>Highlight the model achieving the highest Macro-AUC (best overall discrimination).</li>\n",
    "                <li>Identify any model showing <strong>AUC &lt; 0.5</strong> and explain what it implies (worse-than-random classification).</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Provide a short interpretation discussing how ROC-AUC helps select the most robust classifier independent of any fixed threshold.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089f156-629f-44c9-9a3c-232bb809faa7",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        1. Multi-Class ROC Concept\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Introduce the concept of the <b>Receiver Operating Characteristic (ROC)</b> curve in a <b>multi-class setting</b>.  \n",
    "        Explain how the <b>One-vs-Rest (OvR)</b> approach transforms the problem into multiple binary evaluations for fair comparison.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Define <b>TPR (Recall)</b> and <b>FPR</b> for each class.</li>\n",
    "        <li>Clarify why ROC curves are threshold-based and independent of specific probability cut-offs.</li>\n",
    "        <li>Discuss advantages of macro-averaging for balanced contribution from all classes.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014178f0-27c9-419d-8985-1bd411a6f82c",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #fffde7;\n",
    "    padding: 30px 34px;\n",
    "    margin: 32px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #f9a825;\n",
    "    box-shadow: 0 6px 18px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "\n",
    " <h2 style=\"\n",
    "        font-size: 1.7em;\n",
    "        font-weight: 650;\n",
    "        color: #795548;\n",
    "        margin: 0 0 16px 0;\n",
    "    \">\n",
    "        EXPLANATION: ONE-VS-REST (OvR) APPROACH FOR MULTI-CLASS ROC CURVES\n",
    "    </h2>\n",
    "\n",
    " <h3 style=\"color:#f57f17;margin:14px 0 6px 0;\">What is One-vs-Rest (OvR)?</h3>\n",
    "    <p style=\"color:#4e342e;font-size:0.95em;line-height:1.6;\">\n",
    "        The <b>One-vs-Rest (OvR)</b> or <b>One-vs-All</b> approach extends binary classification metrics, \n",
    "        like ROC–AUC, to multi-class problems.  \n",
    "        It does this by creating one binary classifier per class — each distinguishing a specific class from all the others.\n",
    "    </p>\n",
    "\n",
    " <ul style=\"color:#5d4037;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Class 1 vs. All other classes (2, 3, 4, 5, 6)</li>\n",
    "        <li>Class 2 vs. All other classes (1, 3, 4, 5, 6)</li>\n",
    "        <li>... and so on for all <b>K</b> classes.</li>\n",
    "    </ul>\n",
    "\n",
    " <h3 style=\"color:#f57f17;margin:16px 0 6px 0;\">Why Use OvR for ROC Curves?</h3>\n",
    "    <p style=\"color:#4e342e;font-size:0.95em;line-height:1.6;\">\n",
    "        ROC curves are inherently designed for <b>binary classifiers</b>.  \n",
    "        Using OvR allows each class in a multi-class dataset to be evaluated independently — \n",
    "        ideal for datasets like the <b>6-class Landsat Satellite Dataset</b>.\n",
    "    </p>\n",
    "\n",
    "   <h3 style=\"color:#f57f17;margin:16px 0 6px 0;\">Steps in OvR for ROC Curve Computation</h3>\n",
    "    <ol style=\"color:#4e342e;font-size:0.93em;padding-left:22px;line-height:1.6;\">\n",
    "        <li><b>Binarize Labels:</b>  \n",
    "            For each class \\( k \\), set  \n",
    "            \\( y_k^i = 1 \\) if \\( y^i = k \\); else \\( y_k^i = 0 \\).</li>\n",
    "\n",
    "   <li><b>Predicted Probabilities:</b>  \n",
    "            Use \\( \\hat{y}_k^i = P(\\text{class}=k \\mid x^i) \\) from model outputs.</li>\n",
    "\n",
    "  <li><b>Compute ROC:</b>  \n",
    "            Vary threshold \\( t \\in [0,1] \\), calculate:\n",
    "            <br><br>\n",
    "            <span style=\"background-color:#fff8e1;padding:6px 10px;border-radius:6px;display:inline-block;\">\n",
    "            \\( \\text{TPR}_k(t) = \\frac{TP}{TP + FN} \\)\n",
    "            &nbsp;&nbsp;&nbsp;\n",
    "            \\( \\text{FPR}_k(t) = \\frac{FP}{FP + TN} \\)\n",
    "            </span>\n",
    "        </li>\n",
    "\n",
    " <li><b>Plot:</b>  \n",
    "            Plot \\( \\text{FPR}_k(t) \\) on X-axis vs. \\( \\text{TPR}_k(t) \\) on Y-axis for each class.</li>\n",
    "\n",
    " <li><b>Compute AUC:</b>  \n",
    "            Measure the area under the ROC curve:\n",
    "            <br><br>\n",
    "            <span style=\"background-color:#fff8e1;padding:6px 10px;border-radius:6px;display:inline-block;\">\n",
    "            \\( \\text{AUC}_k = \\int_{0}^{1} \\text{TPR}_k(\\text{FPR}_k^{-1}(x)) \\, dx \\)\n",
    "            </span>\n",
    "        </li>\n",
    "    </ol>\n",
    "\n",
    " <div style=\"\n",
    "        background-color:#fff8e1;\n",
    "        padding:14px 18px;\n",
    "        margin:20px 0;\n",
    "        border-radius:8px;\n",
    "        border-left:4px solid #fbc02d;\n",
    "        font-size:0.9em;\n",
    "        color:#4e342e;\n",
    "        line-height:1.6;\n",
    "    \">\n",
    "        <b>Interpretation:</b>\n",
    "        <ul style=\"margin:8px 0 0 16px;\">\n",
    "            <li>Curve above diagonal → Better than random performance</li>\n",
    "            <li>Curve below diagonal → Worse than random</li>\n",
    "            <li>Steeper curve (closer to top-left) → Better discrimination ability</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "\n",
    " <h3 style=\"color:#f57f17;margin:16px 0 6px 0;\">Aggregating Across Classes</h3>\n",
    "    <ul style=\"color:#4e342e;font-size:0.93em;padding-left:22px;line-height:1.6;\">\n",
    "        <li><b>Macro-Average AUC:</b>  \n",
    "            \\( \\text{AUC}_{macro} = \\frac{1}{K} \\sum_{k=1}^{K} \\text{AUC}_k \\)\n",
    "            — treats all classes equally.</li>\n",
    "   <li><b>Weighted-Average AUC:</b>  \n",
    "           \\( \\text{AUC}_{weighted} = \\frac{\\sum_{k=1}^{K} n_k \\times \\text{AUC}_k}{\\sum_{k=1}^{K} n_k} \\)\n",
    "            — accounts for class imbalance.</li>\n",
    "\n",
    "   <li><b>Micro-Average AUC:</b>  \n",
    "           Combines all predictions into one ROC — gives instance-level averaging.</li>\n",
    "    </ul>\n",
    "\n",
    " <h3 style=\"color:#f57f17;margin:16px 0 6px 0;\">Advantages of OvR</h3>\n",
    "    <ul style=\"color:#4e342e;font-size:0.93em;padding-left:22px;line-height:1.6;\">\n",
    "        <li>Simple and widely compatible with probabilistic classifiers.</li>\n",
    "        <li>Provides detailed per-class discrimination insights.</li>\n",
    "        <li>Handles both balanced and imbalanced datasets effectively.</li>\n",
    "        <li>Highlights which classes are easily separable and which are not.</li>\n",
    "    </ul>\n",
    "    <hr style=\"border:none;border-top:1px solid #f9e79f;margin:22px 0;\">\n",
    "\n",
    " <h3 style=\"color:#f57f17;margin:12px 0 6px 0;\">Mathematical Summary</h3>\n",
    " <div style=\"\n",
    "        background-color:#fff8e1;\n",
    "        padding:16px 18px;\n",
    "        border-radius:8px;\n",
    "        font-family:'Consolas','Courier New',monospace;\n",
    "        font-size:0.9em;\n",
    "        color:#5d4037;\n",
    "        line-height:1.7;\n",
    "        overflow-x:auto;\n",
    "    \">\n",
    "<b>Binary Labels:</b>\n",
    "yₖ⁽ⁱ⁾ ∈ {0,1}, where  \n",
    " yₖ⁽ⁱ⁾ = 1  if  y⁽ⁱ⁾ = k  \n",
    " yₖ⁽ⁱ⁾ = 0  otherwise  \n",
    "\n",
    "<b>Predicted Score:</b>  \n",
    " ŷₖ⁽ⁱ⁾ = P(class = k | x⁽ⁱ⁾)\n",
    "\n",
    "<b>ROC Components:</b>  \n",
    " TPRₖ(t) = TP / (TP + FN)  \n",
    " FPRₖ(t) = FP / (FP + TN)\n",
    "\n",
    "<b>AUC per Class:</b>  \n",
    " AUCₖ = ∫₀¹ TPRₖ(FPRₖ⁻¹(x)) dx\n",
    "\n",
    "<b>Macro-Averaged AUC:</b>  \n",
    " AUCₘₐcᵣₒ = (1/K) Σₖ₌₁ᴷ AUCₖ\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47594209-2dc7-4465-b37d-a262cc60796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get unique classes\n",
    "classes = np.unique(y_train)\n",
    "n_classes = len(classes)\n",
    "\n",
    "# Binarize the labels for OvR approach\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# Dictionary to store ROC data for each model\n",
    "roc_data = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CALCULATING ROC-AUC (One-vs-Rest)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name in trained_models.keys():\n",
    "    print(f\"\\nProcessing: {model_name}\")\n",
    "    \n",
    "    y_prob = probabilities[model_name]\n",
    "    \n",
    "    # Store ROC curve data for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    # Calculate ROC curve and AUC for each class (OvR)\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        print(f\"  Class {classes[i]}: AUC = {roc_auc[i]:.4f}\")\n",
    "    \n",
    "    # Compute micro-average ROC curve and AUC\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binarized.ravel(), y_prob.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Compute macro-average ROC curve and AUC\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    print(f\"  Micro-Average AUC: {roc_auc['micro']:.4f}\")\n",
    "    print(f\"  Macro-Average AUC: {roc_auc['macro']:.4f}\")\n",
    "    \n",
    "    # Store data\n",
    "    roc_data[model_name] = {\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'auc': roc_auc,\n",
    "        'classes': classes\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d863c-73b5-491b-9437-548a5db3179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot ROC curves for all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, model_name in enumerate(trained_models.keys()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    fpr = roc_data[model_name]['fpr']\n",
    "    tpr = roc_data[model_name]['tpr']\n",
    "    roc_auc = roc_data[model_name]['auc']\n",
    "    \n",
    "    # Plot ROC curve for each class\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label=f'Class {classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    # Plot micro and macro averages\n",
    "    ax.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "            label=f'Micro-avg (AUC = {roc_auc[\"micro\"]:.2f})',\n",
    "            linestyle='--', linewidth=2, color='deeppink')\n",
    "    \n",
    "    ax.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "            label=f'Macro-avg (AUC = {roc_auc[\"macro\"]:.2f})',\n",
    "            linestyle='--', linewidth=2, color='navy')\n",
    "    \n",
    "    # Plot random classifier line\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "    \n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC Curves - {model_name}')\n",
    "    ax.legend(loc=\"lower right\", fontsize=8)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table of AUC scores\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: AUC SCORES (MACRO-AVERAGE)\")\n",
    "print(\"=\"*70)\n",
    "for model_name in trained_models.keys():\n",
    "    macro_auc = roc_data[model_name]['auc']['macro']\n",
    "    print(f\"{model_name:30s}: {macro_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f732e-bcad-474a-8a83-af4dfd89d12a",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f1f8e9;\n",
    "    padding: 26px 30px;\n",
    "    margin: 32px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #43a047;\n",
    "    box-shadow: 0 6px 16px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "\n",
    " <h2 style=\"\n",
    "        font-size: 1.6em;\n",
    "        font-weight: 650;\n",
    "        color: #2e7d32;\n",
    "        margin: 0 0 14px 0;\n",
    "    \">\n",
    "        SUMMARY: AUC SCORES (MACRO-AVERAGE)\n",
    "    </h2>\n",
    "\n",
    " <p style=\"\n",
    "     color: #33691e;\n",
    "        font-size: 0.95em;\n",
    "        margin: 0 0 16px 0;\n",
    "        line-height: 1.6;\n",
    "    \">\n",
    "        The table below summarizes the <b>macro-averaged AUC</b> scores for each baseline model, \n",
    "        offering a consolidated view of overall multi-class discrimination performance.\n",
    "    </p>\n",
    "\n",
    "<table style=\"\n",
    "        width: 100%;\n",
    "        border-collapse: collapse;\n",
    "        background-color: #ffffff;\n",
    "        border: 1px solid #c8e6c9;\n",
    "        border-radius: 6px;\n",
    "        overflow: hidden;\n",
    "        font-size: 0.93em;\n",
    "        color: #1b5e20;\n",
    "    \">\n",
    "        <thead style=\"background-color: #a5d6a7; color: #1b5e20;\">\n",
    "            <tr>\n",
    "                <th style=\"padding: 10px 12px; text-align: left;\">Model</th>\n",
    "                <th style=\"padding: 10px 12px; text-align: center;\">Macro-Average AUC</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr><td style=\"padding: 8px 12px;\">K-Nearest Neighbors</td><td style=\"text-align:center;\">0.9786</td></tr>\n",
    "            <tr style=\"background-color:#f9fff7;\"><td style=\"padding: 8px 12px;\">Decision Tree</td><td style=\"text-align:center;\">0.9237</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\">Dummy Classifier (Prior)</td><td style=\"text-align:center;\">0.5000</td></tr>\n",
    "            <tr style=\"background-color:#f9fff7;\"><td style=\"padding: 8px 12px;\">Logistic Regression</td><td style=\"text-align:center;\">0.9542</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\">Naive Bayes (Gaussian)</td><td style=\"text-align:center;\">0.9553</td></tr>\n",
    "            <tr style=\"background-color:#f9fff7;\"><td style=\"padding: 8px 12px;\">Support Vector Machine</td><td style=\"text-align:center;\">0.9852</td></tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    " <div style=\"\n",
    "        margin-top: 18px;\n",
    "        background-color: #dcedc8;\n",
    "        padding: 14px 16px;\n",
    "        border-radius: 6px;\n",
    "        border-left: 4px solid #66bb6a;\n",
    "        color: #2e7d32;\n",
    "        font-size: 0.95em;\n",
    "        line-height: 1.6;\n",
    "    \">\n",
    "        <b>Observations:</b>\n",
    "        <ul style=\"margin:8px 0 0 16px;\">\n",
    "            <li><b>Support Vector Machine (0.9852)</b> achieves the <b>highest AUC</b>, showing excellent class separation.</li>\n",
    "            <li><b>KNN (0.9786)</b> also performs strongly, confirming robust discrimination power.</li>\n",
    "            <li><b>Logistic Regression</b> and <b>Naive Bayes</b> maintain competitive AUCs above 0.95.</li>\n",
    "            <li><b>Decision Tree</b> shows moderate performance due to overfitting tendencies.</li>\n",
    "            <li><b>Dummy Classifier (0.5000)</b> represents random guessing — the expected baseline.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d2160-50fe-4853-9ef5-5701d21eafb9",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow:0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        2. Compute ROC Curves\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Compute class-wise ROC curves for each trained model using predicted probabilities from <code>predict_proba()</code>.  \n",
    "        Each curve shows the trade-off between sensitivity and specificity.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Use <code>roc_curve()</code> and <code>auc()</code> functions from <b>scikit-learn</b>.</li>\n",
    "        <li>Calculate ROC for every class and aggregate using <b>macro-averaging</b>.</li>\n",
    "        <li>Store all AUC scores for later ranking and visualization.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b7f5e-5c9f-4fd6-be6b-79d24e309efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single plot with all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Color-blind friendly palette (Okabe–Ito)\n",
    "colors = ['#0072B2',  # blue\n",
    "          '#E69F00',  # orange\n",
    "          '#009E73',  # green\n",
    "          '#F0E442',  # yellow\n",
    "          '#56B4E9',  # sky blue\n",
    "          '#D55E00']  # vermillion (red-orange)\n",
    "\n",
    "# Plot ROC curve for each model\n",
    "for idx, (model_name, color) in enumerate(zip(trained_models.keys(), colors)):\n",
    "    fpr =  roc_data[model_name]['fpr']['macro']\n",
    "    tpr =  roc_data[model_name]['tpr']['macro']\n",
    "    auc_score = roc_data[model_name]['auc']['macro']\n",
    "    \n",
    "#     fpr = macro_roc_data[model_name]['fpr']\n",
    "#     tpr = macro_roc_data[model_name]['tpr']\n",
    "#     auc_score = macro_roc_data[model_name]['auc']\n",
    "    \n",
    "    plt.plot(fpr, tpr, \n",
    "             color=color, \n",
    "             linewidth=2, \n",
    "             label=f'{model_name} (AUC = {auc_score:.3f})')\n",
    "\n",
    "# Plot random classifier baseline (diagonal line)\n",
    "plt.plot([0, 1], [0, 1], \n",
    "         color='black', \n",
    "         linestyle='--', \n",
    "         linewidth=2, \n",
    "         label='Random Classifier (AUC = 0.500)')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=12, fontweight='bold')\n",
    "plt.title('ROC Curves: Macro-Average (One-vs-Rest) - All Models', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.legend(loc=\"lower right\", fontsize=10, framealpha=0.9)\n",
    "plt.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add a text box explaining what we're seeing\n",
    "textstr = 'Higher AUC = Better Performance\\nCloser to top-left corner = Better'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.text(0.7, 0.3, textstr, fontsize=10, bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c176c-062b-4214-aef1-bfc31f76435d",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow:0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        4. Interpret AUC Results\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Interpret the <b>Area Under Curve (AUC)</b> values to assess each model’s discrimination ability across thresholds.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li><b>AUC ≈ 1:</b> perfect classification.</li>\n",
    "        <li><b>AUC ≈ 0.5:</b> random guessing.</li>\n",
    "        <li><b>AUC &lt; 0.5:</b> inverted prediction (worse than random) — analyze why this occurred.</li>\n",
    "        <li>Rank all models based on macro-AUC and highlight the best and worst performers.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5d3b7-598a-47dd-ba3b-0549354eb499",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #e0f2f1;\n",
    "    padding: 20px 26px;\n",
    "    margin: 28px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #26a69a;\n",
    "    box-shadow: 0 6px 14px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h3 style=\"\n",
    "        font-size: 1.4em;\n",
    "        font-weight: 650;\n",
    "        color: #004d40;\n",
    "        margin: 0 0 12px 0;\n",
    "    \">\n",
    "        ROC Curve Legend — Model AUC Scores\n",
    "    </h3>\n",
    "\n",
    " <p style=\"\n",
    "        color: #004d40;\n",
    "        font-size: 0.94em;\n",
    "        line-height: 1.7;\n",
    "        margin: 0 0 10px 0;\n",
    "    \">\n",
    "        The following summarizes the <b>macro-averaged AUC values</b> for each model as shown in the ROC plot.\n",
    "        Higher AUC values indicate stronger overall class discrimination across all classes.\n",
    "    </p>\n",
    "\n",
    " <table style=\"\n",
    "        width: 100%;\n",
    "        border-collapse: collapse;\n",
    "        background-color: #ffffff;\n",
    "        border: 1px solid #b2dfdb;\n",
    "        border-radius: 6px;\n",
    "        overflow: hidden;\n",
    "        font-size: 0.93em;\n",
    "        color: #004d40;\n",
    "    \">\n",
    "        <thead style=\"background-color: #a7ffeb; color: #004d40;\">\n",
    "            <tr>\n",
    "                <th style=\"padding: 10px 12px; text-align: left;\">Model</th>\n",
    "                <th style=\"padding: 10px 12px; text-align: center;\">AUC (Macro-Average)</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr><td style=\"padding: 8px 12px;\">K-Nearest Neighbors</td><td style=\"text-align:center;\">0.979</td></tr>\n",
    "            <tr style=\"background-color:#f9fffd;\"><td style=\"padding: 8px 12px;\">Decision Tree</td><td style=\"text-align:center;\">0.924</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\">Logistic Regression</td><td style=\"text-align:center;\">0.954</td></tr>\n",
    "            <tr style=\"background-color:#f9fffd;\"><td style=\"padding: 8px 12px;\">Naive Bayes (Gaussian)</td><td style=\"text-align:center;\">0.955</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\">Support Vector Machine</td><td style=\"text-align:center;\">0.985</td></tr>\n",
    "            <tr style=\"background-color:#f9fffd;\"><td style=\"padding: 8px 12px;\">Dummy Classifier (Prior)</td><td style=\"text-align:center;\">0.500</td></tr>\n",
    "            <tr><td style=\"padding: 8px 12px;\">Random Classifier</td><td style=\"text-align:center;\">0.500</td></tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\n",
    " <div style=\"\n",
    "        margin-top: 16px;\n",
    "        background-color: #b2dfdb;\n",
    "        padding: 14px 16px;\n",
    "        border-radius: 6px;\n",
    "        border-left: 4px solid #26a69a;\n",
    "        color: #004d40;\n",
    "        font-size: 0.93em;\n",
    "        line-height: 1.6;\n",
    "    \">\n",
    "        <b>Observations:</b>\n",
    "        <ul style=\"margin:8px 0 0 18px;\">\n",
    "            <li><b>Support Vector Machine (AUC = 0.985)</b> achieves the best ROC performance overall.</li>\n",
    "            <li><b>K-Nearest Neighbors (AUC = 0.979)</b> closely follows, demonstrating high stability.</li>\n",
    "            <li><b>Naive Bayes</b> and <b>Logistic Regression</b> show consistent, reliable performance near 0.95 AUC.</li>\n",
    "            <li><b>Decision Tree</b> performs adequately but shows slight overfitting effects.</li>\n",
    "            <li><b>Dummy</b> and <b>Random Classifiers</b> remain at AUC = 0.5, representing baseline randomness.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d1d502-33f7-4530-b600-7ebe0f91190b",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #e0f7f5;\n",
    "    padding: 28px 32px;\n",
    "    margin: 32px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #26a69a;\n",
    "    box-shadow: 0 6px 16px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h2 style=\"\n",
    "        font-size: 1.6em;\n",
    "        font-weight: 650;\n",
    "        color: #004d40;\n",
    "        margin: 0 0 16px 0;\n",
    "    \">\n",
    "         Combined ROC Curves (Macro-Average OvR) — All Models\n",
    "    </h2>\n",
    "\n",
    "<p style=\"\n",
    "        color: #004d40;\n",
    "        font-size: 0.96em;\n",
    "        line-height: 1.7;\n",
    "        margin: 0 0 14px 0;\n",
    "    \">\n",
    "        This visualization presents the <b>Receiver Operating Characteristic (ROC)</b> curves for all six models \n",
    "        using the <b>One-vs-Rest (OvR)</b> strategy. Each plotted curve represents a \n",
    "        <b>Macro-Average ROC</b> across all classes — averaging True Positive Rate (TPR) and \n",
    "        False Positive Rate (FPR) equally, ensuring fair contribution from every class.\n",
    "    </p>\n",
    "\n",
    " <h3 style=\"color:#00695c;margin:16px 0 8px 0;\">🔍 How This Plot Is Created:</h3>\n",
    "    <ol style=\"color:#004d40;font-size:0.93em;padding-left:24px;line-height:1.7;\">\n",
    "        <li><b>Binarization (OvR approach):</b> Each class is treated as a binary classification task \n",
    "            (<i>one class vs. the rest</i>).</li>\n",
    "        <li><b>Per-Class ROC:</b> For each model and class, compute the ROC curve \n",
    "            using predicted probabilities and true binary labels.</li>\n",
    "        <li><b>Macro-Averaging:</b>  \n",
    "            <ul style=\"margin-top:6px;list-style-type:circle;padding-left:18px;\">\n",
    "                <li>Combine all unique FPR points across classes.</li>\n",
    "                <li>Interpolate corresponding TPR values for each class.</li>\n",
    "                <li>Average interpolated TPRs to form a smooth macro-ROC curve per model.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><b>Plotting:</b>  \n",
    "            - Display all models’ macro-ROC curves on one plot using a \n",
    "            <b>color-blind-friendly Okabe–Ito palette</b>.<br>\n",
    "            - The <b>dashed diagonal line</b> shows a random classifier (<i>AUC = 0.5</i>).<br>\n",
    "            - Each legend entry includes the <b>model’s AUC value</b>.</li>\n",
    "    </ol>\n",
    "\n",
    " <div style=\"\n",
    "        background-color: #b2dfdb;\n",
    "        padding: 16px 20px;\n",
    "        margin: 18px 0;\n",
    "        border-radius: 8px;\n",
    "        border-left: 4px solid #00796b;\n",
    "        color: #004d40;\n",
    "        font-size: 0.94em;\n",
    "        line-height: 1.7;\n",
    "    \">\n",
    "        <b> Why This Visualization Matters:</b>\n",
    "        <ul style=\"margin:8px 0 0 18px;\">\n",
    "            <li><b>Unified Comparison:</b> Displays all models’ ROC curves together for direct visual comparison.</li>\n",
    "            <li><b>Fair Evaluation:</b> Macro-averaging ensures balanced treatment of all classes.</li>\n",
    "            <li><b>Insightful Model Selection:</b>  \n",
    "                <ul style=\"margin-top:4px;list-style-type:circle;\">\n",
    "                    <li>Curves near the <b>top-left corner</b> indicate stronger models (high TPR, low FPR).</li>\n",
    "                    <li>Higher <b>AUC values</b> signify better overall class discrimination.</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </div>\n",
    "\n",
    "<p style=\"\n",
    "        color:#004d40;\n",
    "        font-size:0.95em;\n",
    "        margin-top:12px;\n",
    "        line-height:1.6;\n",
    "    \">\n",
    "        Overall, this macro-averaged ROC comparison provides a comprehensive and equitable assessment of model performance \n",
    "        across all six classes, offering key insight into each classifier’s discriminative ability in a multiclass setting.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5557cfb-67c7-4bb9-9568-69a818d36723",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #e8f5e9;\n",
    "    padding: 26px 30px;\n",
    "    margin: 30px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #43a047;\n",
    "    box-shadow: 0 6px 14px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h2 style=\"\n",
    "        font-size: 1.5em;\n",
    "        font-weight: 650;\n",
    "        color: #1b5e20;\n",
    "        margin: 0 0 14px 0;\n",
    "    \">\n",
    "         ROC Interpretation \n",
    "    </h2>\n",
    "\n",
    " <ol style=\"color:#1b5e20; font-size:0.95em; padding-left:22px; line-height:1.7;\">\n",
    "        <li>\n",
    "            <b>Model with Highest Macro-Averaged AUC:</b><br>\n",
    "            The <b>Support Vector Machine (SVM)</b> achieved the <b>highest macro-averaged AUC of 0.985</b>, \n",
    "            indicating superior capability in distinguishing between classes across the multiclass dataset.  \n",
    "            Its ROC curve stays closest to the top-left corner, reflecting strong sensitivity (TPR) and specificity (low FPR).\n",
    "        </li>\n",
    "\n",
    "  <li style=\"margin-top:12px;\">\n",
    "            <b>Model with AUC &lt; 0.5:</b><br>\n",
    "            The <b>Dummy Classifier (Prior)</b> shows an <b>AUC of 0.500</b>, representing performance equivalent to random guessing.\n",
    "            <br><br>\n",
    "            <b>Conceptual Meaning of AUC &lt; 0.5:</b><br>\n",
    "            - An AUC below 0.5 indicates that the model is performing <b>worse than random chance</b>.<br>\n",
    "            - This means it assigns higher scores to negative samples than to positive ones — effectively <b>reversing class discrimination</b>.<br><br>\n",
    "            <b>Why This Might Occur:</b>\n",
    "            <ul style=\"margin:8px 0 0 20px; list-style-type:circle;\">\n",
    "                <li>Poor model calibration or incorrect class labeling.</li>\n",
    "                <li>Feature–label relationship inversion (e.g., flipped probability logic).</li>\n",
    "                <li>Extremely imbalanced data with improper thresholding or sampling.</li>\n",
    "                <li>Random or constant prediction strategy (as in Dummy Classifier).</li>\n",
    "            </ul>\n",
    "            In practice, an AUC &lt; 0.5 implies that <b>inverting the model’s predictions</b> (flipping labels) could yield a useful classifier.\n",
    "        </li>\n",
    "    </ol>\n",
    "\n",
    " <div style=\"\n",
    "        margin-top:18px;\n",
    "        background-color:#c8e6c9;\n",
    "        padding:14px 16px;\n",
    "        border-left:4px solid #66bb6a;\n",
    "        border-radius:6px;\n",
    "        color:#1b5e20;\n",
    "        font-size:0.94em;\n",
    "        line-height:1.6;\n",
    "    \">\n",
    "        ✅ <b>Summary:</b>  \n",
    "        SVM is the top-performing model based on ROC–AUC, while the Dummy Classifier represents the baseline with AUC = 0.5.\n",
    "        Any model with AUC &lt; 0.5 suggests <b>inverted decision boundaries</b> or <b>non-informative features</b>.\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb8f16-7982-4b53-82bd-bad89b4329fe",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #2b3a4a;\n",
    "    padding: 20px 25px;\n",
    "    margin: 30px 0 20px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #5a9bd5;\n",
    "    box-shadow: 0 4px 10px rgba(0,0,0,0.25);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h2 style=\"\n",
    "        font-size: 1.7em;\n",
    "        font-weight: 600;\n",
    "        color: #ffffff;\n",
    "        margin: 0;\n",
    "        text-shadow: 1px 1px 3px rgba(0,0,0,0.3);\n",
    "    \">\n",
    "         Part C: Precision–Recall Curve (PRC) Analysis\n",
    "    </h2>\n",
    "    <p style=\"\n",
    "        color: #b0bec5;\n",
    "        margin: 8px 0 12px 0;\n",
    "        font-size: 1em;\n",
    "        font-weight: 300;\n",
    "    \">\n",
    "        Perform detailed <strong>Precision–Recall Curve (PRC)</strong> analysis to understand model behavior in terms of\n",
    "        <strong>precision–recall trade-offs</strong>, especially for classes with lower representation or higher overlap.\n",
    "    </p>\n",
    "\n",
    " <ul style=\"color:#d1d5db; margin:0; padding-left:22px; line-height:1.6;\">\n",
    "        <li>Explain why <strong>PRC is often preferred over ROC</strong> for imbalanced classification tasks — PRC focuses on the positive class performance rather than the true negatives dominating ROC.</li>\n",
    "        <li>Compute per-class Precision–Recall pairs using <code>precision_recall_curve()</code> under a <strong>One-vs-Rest (OvR)</strong> framework.</li>\n",
    "        <li>Aggregate these into <strong>macro-averaged PRC curves</strong> for each model to obtain an overall perspective.</li>\n",
    "        <li>Plot the macro-averaged PRC curves for all models on a single figure for visual comparison.</li>\n",
    "        <li>Calculate the <strong>Average Precision (AP)</strong> score for each model and summarize in a comparison table:\n",
    "            <ul style=\"margin-top:6px; color:#b0bec5;\">\n",
    "                <li>Identify the classifier achieving the <strong>highest mean AP (mAP)</strong> value.</li>\n",
    "                <li>Examine the worst-performing model — explain the sharp precision drop as recall increases.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Interpret how PRC complements ROC by emphasizing <strong>predictive reliability for positive instances</strong> and not just ranking ability.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69416a-9791-444c-b156-2015a0863926",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        1. PRC Concept & Motivation\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Introduce the <b>Precision–Recall Curve (PRC)</b> and why it is valuable for multi-class problems—especially when some classes are rare or when we care more about positive predictions. Explain how Precision and Recall trade off as thresholds vary.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Define <b>Precision</b> (positive predictive value) and <b>Recall</b> (sensitivity).</li>\n",
    "        <li>Explain why PRC better reflects performance on the positive class compared to ROC in imbalanced settings.</li>\n",
    "        <li>Note that PRC curves are computed per-class using One-vs-Rest binarization and later aggregated.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a14bc-4fb3-40df-bd9a-a39d609736a0",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#fff8e1;\n",
    "    padding:28px 34px;\n",
    "    margin:28px 0;\n",
    "    border-radius:12px;\n",
    "    border-left:6px solid #fbc02d;\n",
    "    box-shadow:0 6px 16px rgba(0,0,0,0.1);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "\n",
    "<h2 style=\"color:#795548;font-weight:700;font-size:1.6em;margin-top:0;\">Understanding the Metrics</h2>\n",
    "\n",
    "<h3 style=\"color:#5d4037;margin-bottom:6px;\">ROC Curve Components:</h3>\n",
    "<table style=\"width:100%;border-collapse:collapse;font-size:0.95em;margin-bottom:18px;\">\n",
    "<tr style=\"background:#ffecb3;\">\n",
    "<th style=\"padding:8px;border:1px solid #fbc02d;\">Metric</th>\n",
    "<th style=\"padding:8px;border:1px solid #fbc02d;\">Formula</th>\n",
    "<th style=\"padding:8px;border:1px solid #fbc02d;\">What It Measures</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\"><b>True Positive Rate (TPR)</b></td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">TPR = TP / (TP + FN)</td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">Recall: % of actual positives correctly identified</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\"><b>False Positive Rate (FPR)</b></td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">FPR = FP / (FP + TN)</td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">% of actual negatives incorrectly classified as positive</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<h3 style=\"color:#5d4037;margin-bottom:6px;\">Precision–Recall Curve Components:</h3>\n",
    "<table style=\"width:100%;border-collapse:collapse;font-size:0.95em;\">\n",
    "<tr style=\"background:#ffecb3;\">\n",
    "<th style=\"padding:8px;border:1px solid #fbc02d;\">Metric</th>\n",
    "<th style=\"padding:8px;border:1px solid #fbc02d;\">Formula</th>\n",
    "<th style=\"padding:8px;border:1px solid #fbc02d;\">What It Measures</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\"><b>Precision</b></td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">Precision = TP / (TP + FP)</td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">% of predicted positives that are actually positive</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\"><b>Recall (TPR)</b></td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">Recall = TP / (TP + FN)</td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">% of actual positives correctly identified</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<hr style=\"border:none;border-top:2px solid #ffe082;margin:24px 0;\">\n",
    "\n",
    "<h3 style=\"color:#f57f17;\"> The Critical Difference: Role of True Negatives (TN)</h3>\n",
    "<p style=\"color:#5d4037;font-size:0.95em;line-height:1.7;\">\n",
    "ROC includes <b>TN</b> in <b>FPR</b> → \n",
    "<code style=\"background:#fff3e0;color:#e65100;padding:2px 5px;border-radius:4px;\">FPR = FP / (FP + TN)</code><br>\n",
    "PRC ignores TN in <b>Precision</b> → \n",
    "<code style=\"background:#fff3e0;color:#e65100;padding:2px 5px;border-radius:4px;\">Precision = TP / (TP + FP)</code><br><br>\n",
    "➡️ In imbalanced datasets, ROC may appear deceptively good due to a large number of True Negatives, whereas PRC focuses purely on positive class reliability.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:none;border-top:2px solid #ffe082;margin:24px 0;\">\n",
    "\n",
    "<h3 style=\"color:#f57f17;\">Example: Medical Disease Detection (Imbalanced Data)</h3>\n",
    "<p style=\"color:#5d4037;font-size:0.95em;line-height:1.7;\">\n",
    "Suppose only <b>10 patients</b> have the disease out of <b>10,000 people</b> (0.1% positives).  \n",
    "We compare <b>Model A (many false positives)</b> and <b>Model B (few false positives)</b>.\n",
    "</p>\n",
    "\n",
    "<div style=\"background:#fffde7;border-left:5px solid #fdd835;padding:12px 18px;margin:12px 0;border-radius:8px;\">\n",
    "<b>Model A:</b> TP=8, FP=500 ⇒ Precision=1.6%, Recall=80%  \n",
    "<br><b>Model B:</b> TP=8, FP=10 ⇒ Precision=44%, Recall=80%\n",
    "</div>\n",
    "\n",
    "<p style=\"color:#5d4037;font-size:0.95em;\">\n",
    "ROC shows both have high TPR (0.8), but hides the massive 50× difference in false positives.<br>\n",
    "PRC clearly reveals the gap — precision falls drastically for Model A.\n",
    "</p>\n",
    "\n",
    "<hr style=\"border:none;border-top:2px solid #ffe082;margin:24px 0;\">\n",
    "\n",
    "<h3 style=\"color:#f57f17;\"> When to Use Each Curve</h3>\n",
    "<table style=\"width:100%;border-collapse:collapse;font-size:0.95em;\">\n",
    "<tr style=\"background:#ffecb3;\">\n",
    "<th style=\"padding:8px;border:1px solid #fbc02d;\">Use ROC Curve When</th>\n",
    "<th style=\"padding:8px;border:1px solid #fbc02d;\">Use PRC Curve When</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">\n",
    "✅ Balanced datasets (40–60%)<br>\n",
    "✅ Both classes equally important<br>\n",
    "✅ True Negatives are relevant<br>\n",
    "✅ Similar FP and FN costs\n",
    "</td>\n",
    "<td style=\"padding:8px;border:1px solid #fbc02d;\">\n",
    "✅ Highly imbalanced datasets<br>\n",
    "✅ Focus on positive/minority class<br>\n",
    "✅ False positives are costly<br>\n",
    "✅ TNs are abundant and uninformative\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<hr style=\"border:none;border-top:2px solid #ffe082;margin:24px 0;\">\n",
    "\n",
    "<h3 style=\"color:#f57f17;\">Mathematical Clarity</h3>\n",
    "<pre style=\"background:#fff3e0;padding:14px;border-radius:8px;border-left:4px solid #fbc02d;font-size:0.9em;overflow-x:auto;\">\n",
    "FPR = FP / (FP + TN)\n",
    "# When TN >> FP, FPR stays small even if FP is large\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "# Every FP immediately reduces precision\n",
    "</pre>\n",
    "\n",
    "<hr style=\"border:none;border-top:2px solid #ffe082;margin:24px 0;\">\n",
    "\n",
    "<h3 style=\"color:#f57f17;\"> Summary</h3>\n",
    "<ul style=\"color:#5d4037;line-height:1.7;font-size:0.95em;\">\n",
    "<li><b>ROC</b> evaluates overall discrimination (good for balanced data).</li>\n",
    "<li><b>PRC</b> highlights reliability of positive predictions (vital for imbalanced data).</li>\n",
    "<li>ROC may appear optimistic when negatives dominate.</li>\n",
    "<li>PRC gives a more realistic view by ignoring True Negatives.</li>\n",
    "</ul>\n",
    "\n",
    "<div style=\"background:#fffde7;border-left:5px solid #fdd835;padding:14px 18px;border-radius:8px;color:#5d4037;margin-top:14px;font-size:0.94em;\">\n",
    "✨ <b>In summary:</b>  \n",
    "Use <b>ROC</b> when data is balanced,  \n",
    "Use <b>PRC</b> when positive class is rare and crucial.  \n",
    "PRC directly reflects how trustworthy your positive predictions are.\n",
    "</div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58985ff7-be26-4b17-be1e-7e085c9e080d",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        2. Compute Per-Class PRC\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Compute precision–recall pairs for each class using model probability scores. Use scikit-learn's <code>precision_recall_curve()</code> and <code>average_precision_score()</code> to quantify area under the PRC.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>For each class, treat it as positive and the rest as negative (OvR).</li>\n",
    "        <li>Compute precision and recall arrays for different thresholds and the corresponding AP (Average Precision).</li>\n",
    "        <li>Save per-class APs for macro-averaging and reporting.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b6e625-5e8c-4298-835e-d2f2f4ab2db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the labels for One-vs-Rest approach\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CALCULATING PRECISION-RECALL CURVES (One-vs-Rest)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dictionary to store macro-average PRC data for each model\n",
    "macro_prc_data = {}\n",
    "\n",
    "# Process each model\n",
    "for model_name in trained_models.keys():\n",
    "    print(f\"\\nProcessing: {model_name}\")\n",
    "    \n",
    "    # Get predicted probabilities for this model\n",
    "    y_prob = probabilities[model_name]\n",
    "    \n",
    "    # Initialize dictionaries to store per-class PRC data\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    \n",
    "    # Calculate Precision-Recall curve for each class (One-vs-Rest)\n",
    "    for i in range(n_classes):\n",
    "        # For class i: compare class i vs all other classes\n",
    "        precision[i], recall[i], _ = precision_recall_curve(\n",
    "            y_test_binarized[:, i], \n",
    "            y_prob[:, i]\n",
    "        )\n",
    "        # Calculate Average Precision (AP) - area under PR curve\n",
    "        average_precision[i] = average_precision_score(\n",
    "            y_test_binarized[:, i], \n",
    "            y_prob[:, i]\n",
    "        )\n",
    "        print(f\"  Class {classes[i]}: AP = {average_precision[i]:.4f}\")\n",
    "    \n",
    "    # Compute MACRO-AVERAGE Precision-Recall curve\n",
    "    # Step 1: Create a common set of recall values (from 0 to 1)\n",
    "    all_recall = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # Step 2: Interpolate precision values for each class at these recall points\n",
    "    mean_precision = np.zeros_like(all_recall)\n",
    "    for i in range(n_classes):\n",
    "        # Precision-Recall curves go from high recall to low recall\n",
    "        # We need to reverse them for interpolation\n",
    "        # Also, np.interp requires x values to be increasing\n",
    "        mean_precision += np.interp(\n",
    "            all_recall, \n",
    "            recall[i][::-1],  # Reverse recall (make it increasing)\n",
    "            precision[i][::-1]  # Reverse precision accordingly\n",
    "        )\n",
    "    \n",
    "    # Step 3: Average the precision values across all classes\n",
    "    mean_precision /= n_classes\n",
    "    \n",
    "    # Step 4: Calculate macro-average AP (simple average of per-class APs)\n",
    "    macro_ap = np.mean(list(average_precision.values()))\n",
    "    \n",
    "    print(f\"  MACRO-AVERAGE AP: {macro_ap:.4f}\")\n",
    "    \n",
    "    # Store the macro-average data\n",
    "    macro_prc_data[model_name] = {\n",
    "        'recall': all_recall,\n",
    "        'precision': mean_precision,\n",
    "        'average_precision': macro_ap\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee25779-b546-4004-88e6-132c8366256a",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        3. Plot Macro-Averaged PRC\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Aggregate per-class PRC information into a macro-averaged curve and plot all models together to compare Average Precision (AP) visually.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>Interpolate precision values at common recall points and average across classes to form the macro-PRC.</li>\n",
    "        <li>Plot each model’s macro-PRC on the same axes and annotate with macro AP values.</li>\n",
    "        <li>Prefer AP (area under PRC) over simple AUC when class imbalance or positive-class focus matters.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca31c7c-20bf-422a-ac06-31d09965eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING COMBINED PRECISION-RECALL PLOT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create a single plot with all models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "# Calculate baseline (random classifier performance)\n",
    "# For balanced classes, baseline = 1/n_classes\n",
    "# For our data, we'll calculate the actual positive class frequency\n",
    "baseline_precision = np.sum(y_test_binarized) / (len(y_test) * n_classes)\n",
    "\n",
    "\n",
    "# Plot Precision-Recall curve for each model\n",
    "for idx, (model_name, color) in enumerate(zip(trained_models.keys(), colors)):\n",
    "    recall = macro_prc_data[model_name]['recall']\n",
    "    precision = macro_prc_data[model_name]['precision']\n",
    "    ap_score = macro_prc_data[model_name]['average_precision']\n",
    "    \n",
    "    plt.plot(recall, precision, \n",
    "             color=color, \n",
    "             linewidth=2, \n",
    "             label=f'{model_name} (AP = {ap_score:.3f})')\n",
    "\n",
    "# Plot baseline (random classifier)\n",
    "plt.plot([0, 1], [baseline_precision, baseline_precision], \n",
    "         color='black', \n",
    "         linestyle='--', \n",
    "         linewidth=2, \n",
    "         label=f'Random Classifier (AP = {baseline_precision:.3f})')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall (True Positive Rate)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Precision', fontsize=12, fontweight='bold')\n",
    "plt.title('Precision-Recall Curves: Macro-Average (One-vs-Rest) - All Models', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.legend(loc=\"best\", fontsize=10, framealpha=0.9)\n",
    "plt.grid(alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add a text box explaining the plot\n",
    "textstr = 'Higher AP = Better Performance\\nCloser to top-right corner = Better\\nPrecision at high recall = Critical'\n",
    "props = dict(boxstyle='round', facecolor='lightblue', alpha=0.5)\n",
    "plt.text(0.02, 0.15, textstr, fontsize=10, bbox=props, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary ranking\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL RANKING BY MACRO-AVERAGE AP (AVERAGE PRECISION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sort models by AP score (descending)\n",
    "sorted_models = sorted(macro_prc_data.items(), \n",
    "                       key=lambda x: x[1]['average_precision'], \n",
    "                       reverse=True)\n",
    "\n",
    "for rank, (model_name, data) in enumerate(sorted_models, 1):\n",
    "    print(f\"{rank}. {model_name:30s}: AP = {data['average_precision']:.4f}\")\n",
    "\n",
    "# Additional analysis: Compare PRC vs ROC rankings\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: ROC AUC vs PRECISION-RECALL AP\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model Name':<30s} {'ROC AUC':<12s} {'PR AP':<12s} {'Difference':<12s}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for model_name in trained_models.keys():\n",
    "    roc_auc = roc_data[model_name]['auc']['macro']\n",
    "    pr_ap = macro_prc_data[model_name]['average_precision']\n",
    "    diff = roc_auc - pr_ap\n",
    "    print(f\"{model_name:<30s} {roc_auc:<12.4f} {pr_ap:<12.4f} {diff:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd24acd-a0b4-4315-9e36-97a001fc3136",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        4. Interpret AP and PRC Behavior\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Use Average Precision (AP) to rank models by their precision–recall trade-offs. Analyze sharp drops in precision at higher recall as indicators of models making many false positives when trying to capture more positives.\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>High AP → model maintains precision while increasing recall; desirable for positive-class focus.</li>\n",
    "        <li>Sharp precision decline as recall rises → model struggles to distinguish positives without many false alarms.</li>\n",
    "        <li>Compare AP ranking against ROC-AUC and F1 to reveal complementary strengths/weaknesses.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536714d9-2e67-4a3a-834c-fcfe7f37e58d",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #e8faf5;\n",
    "    padding: 26px 30px;\n",
    "    margin: 28px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #20bfa6;\n",
    "    box-shadow: 0 6px 18px rgba(0,0,0,0.06);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "    color: #044d43;\n",
    "\">\n",
    "\n",
    "  <h2 style=\"font-size:1.4em; margin:0 0 10px 0; color:#00796b;\"> PRC Interpretation — Macro-Average AP</h2>\n",
    "\n",
    "  <p style=\"margin:6px 0 16px 0; color:#065a4f;\">\n",
    "    Summary of model performance using <strong>Precision–Recall</strong> analysis (macro-averaged Average Precision — AP).  \n",
    "    AP emphasizes positive-class prediction quality, making it ideal for multiclass scenarios where per-class precision matters.\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"margin:0 0 8px 0; color:#00796b; font-size:1.05em;\">🏆 Model Rankings (Macro-Average AP)</h3>\n",
    "\n",
    "  <table style=\"width:100%; border-collapse:collapse; margin-top:10px; font-size:0.95em;\">\n",
    "    <thead style=\"background:#b2f0e3; color:#004d40;\">\n",
    "      <tr>\n",
    "        <th style=\"padding:10px 12px; text-align:left;\">Rank</th>\n",
    "        <th style=\"padding:10px 12px; text-align:left;\">Model</th>\n",
    "        <th style=\"padding:10px 12px; text-align:center;\">Macro-Average AP</th>\n",
    "        <th style=\"padding:10px 12px; text-align:left;\">Performance</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr><td style=\"padding:8px 12px;\">1</td><td style=\"padding:8px 12px;\">K-Nearest Neighbors</td><td style=\"text-align:center;\">0.9217</td><td style=\"padding:8px 12px;\">Excellent ⭐⭐⭐⭐⭐</td></tr>\n",
    "      <tr style=\"background:#f6fffb;\"><td style=\"padding:8px 12px;\">2</td><td style=\"padding:8px 12px;\">Support Vector Machine</td><td style=\"text-align:center;\">0.9177</td><td style=\"padding:8px 12px;\">Excellent ⭐⭐⭐⭐⭐</td></tr>\n",
    "      <tr><td style=\"padding:8px 12px;\">3</td><td style=\"padding:8px 12px;\">Logistic Regression</td><td style=\"text-align:center;\">0.8116</td><td style=\"padding:8px 12px;\">Very Good ⭐⭐⭐⭐</td></tr>\n",
    "      <tr style=\"background:#f6fffb;\"><td style=\"padding:8px 12px;\">4</td><td style=\"padding:8px 12px;\">Naive Bayes (Gaussian)</td><td style=\"text-align:center;\">0.8106</td><td style=\"padding:8px 12px;\">Very Good ⭐⭐⭐⭐</td></tr>\n",
    "      <tr><td style=\"padding:8px 12px;\">5</td><td style=\"padding:8px 12px;\">Decision Tree</td><td style=\"text-align:center;\">0.7838</td><td style=\"padding:8px 12px;\">Good ⭐⭐⭐</td></tr>\n",
    "      <tr style=\"background:#f6fffb;\"><td style=\"padding:8px 12px;\">6</td><td style=\"padding:8px 12px;\">Dummy Classifier (Prior)</td><td style=\"text-align:center;\">0.1667</td><td style=\"padding:8px 12px;\">Poor (Baseline) ⚠️</td></tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "\n",
    "  <hr style=\"border:none; border-top:1px solid #c8efe8; margin:16px 0;\">\n",
    "\n",
    "  <h3 style=\"margin:0 0 8px 0; color:#00796b;\">🏆 Best Model — KNN (AP = 0.9217)</h3>\n",
    "\n",
    "  <p style=\"margin:6px 0 10px 0;\">\n",
    "    <strong>K-Nearest Neighbors (KNN)</strong> achieves the highest macro-averaged AP (<strong>0.9217</strong>), indicating an excellent precision–recall trade-off across classes.\n",
    "  </p>\n",
    "\n",
    "  <div style=\"background:#ddf7f0; padding:12px 14px; border-radius:8px; border-left:4px solid #20bfa6; color:#044d43;\">\n",
    "    <strong>Practical interpretation:</strong>\n",
    "    <ul style=\"margin:8px 0 0 18px;\">\n",
    "      <li>Out of 100 positive predictions, ~92 are correct (∼92% precision).</li>\n",
    "      <li>KNN maintains high recall (>80%) while keeping precision high — few false positives.</li>\n",
    "      <li>Reasons for KNN's strength:\n",
    "        <ul style=\"margin:6px 0 0 18px;\">\n",
    "          <li>Local decision boundaries and non-parametric flexibility</li>\n",
    "          <li>Natural probability estimates from neighbor counts → well-calibrated scores</li>\n",
    "          <li>Robustness to varying class densities under OvR</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <hr style=\"border:none; border-top:1px solid #c8efe8; margin:16px 0;\">\n",
    "\n",
    "  <h3 style=\"margin:0 0 8px 0; color:#00796b;\">⚠️ Worst Model — Dummy Classifier (AP = 0.1667)</h3>\n",
    "\n",
    "  <p style=\"margin:6px 0 10px 0;\">\n",
    "    The Dummy Classifier (Prior) performs at baseline (AP ≈ class-frequency), producing mostly random predictions and poor PRC behavior.\n",
    "  </p>\n",
    "\n",
    "  <div style=\"background:#fff9f2; padding:12px 14px; border-radius:8px; border-left:4px solid #ffd180; color:#5a4a31;\">\n",
    "    <strong>Why its PRC drops sharply at high recall:</strong>\n",
    "    <ul style=\"margin:8px 0 0 18px;\">\n",
    "      <li>It predicts using only class frequencies (no features); probabilities are random and uninformative.</li>\n",
    "      <li>To achieve high recall, it must predict many positives → yields many false positives → precision collapses.</li>\n",
    "      <li>At extreme recall, precision converges to the class base-rate (≈0.167 here).</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <hr style=\"border:none; border-top:1px solid #c8efe8; margin:16px 0;\">\n",
    "\n",
    "  <h3 style=\"margin:0 0 8px 0; color:#00796b;\"> Additional Notes</h3>\n",
    "\n",
    "  <ul style=\"color:#044d43; margin-left:18px; line-height:1.6;\">\n",
    "    <li>The AP difference between KNN (0.9217) and SVM (0.9177) is negligible — both are excellent choices.</li>\n",
    "    <li>Use PRC when the focus is on precision of positive predictions (e.g., rare classes or costly false positives).</li>\n",
    "    <li>Inspect per-class PR curves to identify which specific classes cause drops in macro-AP and investigate class-wise remedies (resampling, class-specific thresholds).</li>\n",
    "  </ul>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b496a85-41ed-4698-8043-cbc0ce7e7974",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #f0f4f8;\n",
    "    padding: 18px 22px;\n",
    "    margin: 18px 0;\n",
    "    border-radius: 8px;\n",
    "    border-left: 5px solid #42a5f5;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        5. PRC Insights & Recommendations\n",
    "    </h3>\n",
    "    <p style=\"color:#546e7a;margin:0 0 10px 0;font-size:0.95em;line-height:1.6;\">\n",
    "        Summarize PRC-led findings and recommend models depending on whether the task prioritizes precision (low false positives) or recall (capture more positives).\n",
    "    </p>\n",
    "    <ul style=\"color:#546e7a;font-size:0.9em;padding-left:22px;list-style-type:square;\">\n",
    "        <li>If positive-class precision is critical (e.g., costly false alarms), prioritize the model with highest AP.</li>\n",
    "        <li>If recall is prioritized (e.g., detecting rare land-cover types), choose models that sustain reasonable precision at higher recall thresholds.</li>\n",
    "        <li>Use PRC alongside ROC and F1 to form a balanced model selection strategy tailored to deployment needs.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e27e1-3515-449e-8364-59be339d13a4",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #fff8e1;\n",
    "    padding: 24px 28px;\n",
    "    margin: 28px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #fbc02d;\n",
    "    box-shadow: 0 6px 18px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "    color: #4e342e;\n",
    "\">\n",
    "  <h2 style=\"font-size:1.4em; font-weight:600; color:#795548; margin:0 0 10px 0;\">\n",
    "       PRC Insights & Recommendations\n",
    "  </h2>\n",
    "\n",
    "  <p style=\"margin:8px 0 12px 0; font-size:0.95em; line-height:1.6;\">\n",
    "      Precision–Recall Curve (PRC) analysis provides deeper insight into model reliability for \n",
    "      <strong>positive-class detection</strong>, particularly under class imbalance. \n",
    "      By emphasizing <strong>Precision</strong> and <strong>Recall</strong> rather than True Negatives, \n",
    "      PRC helps identify models that minimize false alarms or maximize correct detections based on task priorities.\n",
    "  </p>\n",
    "\n",
    "  <ul style=\"margin:10px 0 0 18px; font-size:0.95em; line-height:1.7;\">\n",
    "      <li>\n",
    "          <strong>If precision is critical</strong> — e.g., when <em>false positives are costly</em> (fraud detection, medical screening) — \n",
    "          choose models with the <strong>highest Average Precision (AP)</strong>.  \n",
    "          <br>💡 In this study: <b>K-Nearest Neighbors (AP = 0.9217)</b> is the most reliable choice for precision-focused applications.\n",
    "      </li>\n",
    "\n",
    "<li style=\"margin-top:10px;\">\n",
    "          <strong>If recall is the priority</strong> — e.g., when <em>missing positives is unacceptable</em> \n",
    "          (rare class detection, environmental mapping) — select models that maintain <strong>reasonable precision at high recall</strong> thresholds.  \n",
    "          <br>💡 <b>SVM and Logistic Regression</b> are strong candidates due to stable performance across recall ranges.\n",
    "      </li>\n",
    "\n",
    " <li style=\"margin-top:10px;\">\n",
    "          <strong>Balanced strategy:</strong>  \n",
    "          Combine <b>PRC</b> with <b>ROC–AUC</b> and <b>F1-Score</b> to form a comprehensive model selection framework \n",
    "          tailored to deployment needs.  \n",
    "          <br>⚖️ This ensures the chosen model aligns with the real-world trade-offs between \n",
    "          <em>false alarms, missed detections, and overall reliability</em>.\n",
    "      </li>\n",
    "  </ul>\n",
    "\n",
    "  <p style=\"margin-top:16px; color:#6d4c41; font-size:0.9em;\">\n",
    "      ✨ <strong>Summary:</strong>  \n",
    "      Use PRC-led evaluation to uncover the model’s true positive prediction quality.  \n",
    "      Prioritize KNN for precision-sensitive applications and SVM/Logistic Regression for recall-oriented tasks, \n",
    "      integrating all three metrics (PRC, ROC, F1) for a robust final choice.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7b143-763a-4484-bfe4-8a4db6409f69",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #2b3a4a;\n",
    "    padding: 20px 25px;\n",
    "    margin: 30px 0 20px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #5a9bd5;\n",
    "    box-shadow: 0 4px 10px rgba(0,0,0,0.25);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h2 style=\"\n",
    "        font-size: 1.7em;\n",
    "        font-weight: 600;\n",
    "        color: #ffffff;\n",
    "        margin: 0;\n",
    "        text-shadow: 1px 1px 3px rgba(0,0,0,0.3);\n",
    "    \">\n",
    "         Part D: Final Recommendation & Comparative Insights\n",
    "    </h2>\n",
    "    <p style=\"\n",
    "        color: #b0bec5;\n",
    "        margin: 8px 0 12px 0;\n",
    "        font-size: 1em;\n",
    "        font-weight: 300;\n",
    "    \">\n",
    "        Consolidate findings from <strong>Accuracy</strong>, <strong>F1-Score</strong>, \n",
    "        <strong>ROC-AUC</strong>, and <strong>Average Precision (AP)</strong> analyses \n",
    "        to recommend the most suitable model for deployment.  \n",
    "        Discuss trade-offs between performance, interpretability, and generalization.\n",
    "    </p>\n",
    "\n",
    " <ul style=\"color:#d1d5db; margin:0; padding-left:22px; line-height:1.6;\">\n",
    "        <li><strong>Summarize model metrics</strong> — create a comparison table containing Accuracy, F1, AUC, and AP for every classifier.</li>\n",
    "        <li><strong>Check ranking consistency</strong> across metrics to find stable top performers; inconsistent ranks may indicate metric sensitivity.</li>\n",
    "        <li><strong>Discuss trade-offs</strong> between high recall vs. precision, ROC vs. PRC stability, and computation vs. interpretability.</li>\n",
    "        <li><strong>Select the final model</strong> balancing statistical performance with operational practicality (speed, explainability, robustness).</li>\n",
    "        <li>Provide a <strong>deployment recommendation</strong> including brief notes on reproducibility, scalability, and potential improvements \n",
    "            such as tuning, calibration, or ensembling.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadee28c-26b8-4b3e-a47a-8f24c17f58c8",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#f0f4f8;\n",
    "    padding:18px 22px;\n",
    "    margin:18px 0;\n",
    "    border-radius:8px;\n",
    "    border-left:5px solid #42a5f5;\n",
    "    box-shadow:0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    " 1. Synthesis    </h3>\n",
    "    Comparing model rankings across <b>F1-Score</b>, <b>ROC-AUC</b>, and <b>PRC-AP</b> highlights complementary insights.  \n",
    "      While <b>ROC-AUC</b> captures ranking quality over all thresholds, <b>PRC-AP</b> stresses reliability of positive predictions.  \n",
    "      Thus, models like <b>SVM</b> and <b>KNN</b> excel consistently across metrics, whereas others may score high on ROC but lag on PRC due to sensitivity to class imbalance.\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46deac-0332-4ee7-bf52-5ccb58d4e963",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#e3f2fd;\n",
    "    padding:26px 30px;\n",
    "    margin:30px 0;\n",
    "    border-radius:10px;\n",
    "    border-left:6px solid #42a5f5;\n",
    "    box-shadow:0 6px 18px rgba(0,0,0,0.08);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "    color:#0d47a1;\n",
    "\">\n",
    "\n",
    "\n",
    "  <h2 style=\"font-size:1.2em;font-weight:600;color:#1976d2;margin:10px 0;\">🏆 The Rankings Showdown</h2>\n",
    "  <p style=\"font-size:0.95em;line-height:1.6;margin:0 0 12px 0;\">\n",
    "      This synthesis compares model rankings from <b>F1-Score</b>, <b>ROC-AUC</b>, and <b>PRC-AP</b> analyses, revealing both consistency among top models and key trade-offs for mid-tier ones.\n",
    "  </p>\n",
    "\n",
    "  <table style=\"width:100%;border-collapse:collapse;margin-top:8px;font-size:0.9em;\">\n",
    "    <thead style=\"background:#bbdefb;color:#0d47a1;\">\n",
    "      <tr>\n",
    "        <th style=\"padding:8px 12px;text-align:left;\">Rank</th>\n",
    "        <th style=\"padding:8px 12px;text-align:left;\">F1-Score (Weighted)</th>\n",
    "        <th style=\"padding:8px 12px;text-align:left;\">ROC-AUC (Macro)</th>\n",
    "        <th style=\"padding:8px 12px;text-align:left;\">PRC-AP (Macro)</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr><td style=\"padding:6px 12px;\">1st</td><td>🥇 K-Nearest Neighbors (0.9037)</td><td>🥇 Support Vector Machine (0.9852)</td><td>🥇 K-Nearest Neighbors (0.9217)</td></tr>\n",
    "      <tr style=\"background:#f7fbff;\"><td>2nd</td><td>🥈 Support Vector Machine (0.8925)</td><td>🥈 K-Nearest Neighbors (0.9786)</td><td>🥈 Support Vector Machine (0.9177)</td></tr>\n",
    "      <tr><td>3rd</td><td>🥉 Decision Tree (0.8558)</td><td>🥉 Naive Bayes (0.9553)</td><td>🥉 Logistic Regression (0.8116)</td></tr>\n",
    "      <tr style=\"background:#f7fbff;\"><td>4th</td><td>Naive Bayes (0.8036)</td><td>Logistic Regression (0.9542)</td><td>Naive Bayes (0.8106)</td></tr>\n",
    "      <tr><td>5th</td><td>Logistic Regression (0.7935)</td><td>Decision Tree (0.9237)</td><td>Decision Tree (0.7838)</td></tr>\n",
    "      <tr style=\"background:#f7fbff;\"><td>6th</td><td>Dummy Classifier (0.0864)</td><td>Dummy Classifier (0.5000)</td><td>Dummy Classifier (0.1667)</td></tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "\n",
    "  <hr style=\"border:none;border-top:1px solid #bbdefb;margin:16px 0;\">\n",
    "\n",
    "  <h3 style=\"color:#1565c0;\">✅ Consistent Trends</h3>\n",
    "  <p style=\"margin:0 0 8px 0;\">\n",
    "      <b>K-Nearest Neighbors</b> and <b>Support Vector Machine</b> dominate across metrics:\n",
    "      <ul style=\"margin:6px 0 0 20px;line-height:1.6;\">\n",
    "        <li><b>KNN</b>: #1 in F1 and PRC-AP, #2 in ROC-AUC</li>\n",
    "        <li><b>SVM</b>: #1 in ROC-AUC, #2 in F1 and PRC-AP</li>\n",
    "        <li>Both show robust, threshold-independent performance → reliable choices.</li>\n",
    "      </ul>\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"color:#1565c0;margin-top:14px;\">⚠️ Divergent Patterns</h3>\n",
    "  <ul style=\"margin-left:18px;line-height:1.6;\">\n",
    "      <li><b>Naive Bayes:</b> Excellent ROC (0.9553) but weaker PRC-AP (0.8106) — suffers from overconfidence and poor calibration.</li>\n",
    "      <li><b>Decision Tree:</b> High F1 (0.8558) at default threshold but low ROC/PRC due to overfitting and poor probability scaling.</li>\n",
    "      <li><b>Logistic Regression:</b> Lower F1 (0.7935) yet strong PRC-AP (0.8116) — precise and stable, though less recall-sensitive.</li>\n",
    "  </ul>\n",
    "\n",
    "  <div style=\"background:#f1f8ff;border-left:4px solid #42a5f5;padding:12px 14px;border-radius:6px;margin-top:10px;\">\n",
    "    <strong>Key Insight:</strong>  \n",
    "    F1 focuses on a single threshold, ROC-AUC captures ranking power, and PRC-AP reveals practical precision.  \n",
    "    Hence, rankings partially align but diverge where models differ in calibration and threshold adaptability.\n",
    "  </div>\n",
    "\n",
    "  <p style=\"margin-top:16px;font-size:0.9em;color:#0d47a1;\">\n",
    "      🎯 <b>Summary:</b> Top performers (KNN, SVM) remain consistent across all evaluations, while Naive Bayes, Decision Tree, and Logistic Regression exhibit metric-specific strengths and weaknesses due to their sensitivity to thresholds, overfitting, and probability calibration.\n",
    "  </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcdcccc-8a80-450c-9677-132693184951",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#f0f4f8;\n",
    "    padding:18px 22px;\n",
    "    margin:18px 0;\n",
    "    border-radius:8px;\n",
    "    border-left:5px solid #42a5f5;\n",
    "    box-shadow:0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "        2.  Recommendation\n",
    "    </h3>\n",
    "    <p style=\"margin:0;line-height:1.6;font-size:0.95em;\">\n",
    "      Considering performance across <b>ROC-AUC</b>, <b>PRC-AP</b>, and <b>F1-Score</b>,  \n",
    "      <b>K-Nearest Neighbors (KNN)</b> offers the most balanced trade-off between <b>precision</b> and <b>recall</b>,  \n",
    "      delivering top scores on both AUC and AP.  \n",
    "      It is best suited for applications requiring <em>balanced decision reliability</em>.  \n",
    "      <b>SVM</b> remains a strong secondary choice for recall-focused or high-sensitivity tasks.\n",
    "  </p>\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd1d58-a9b0-4176-9c77-0a0c43666c65",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#e3f2fd;\n",
    "    padding:26px 30px;\n",
    "    margin:30px 0;\n",
    "    border-radius:10px;\n",
    "    border-left:6px solid #42a5f5;\n",
    "    box-shadow:0 6px 18px rgba(0,0,0,0.08);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "    color:#0d47a1;\n",
    "\">\n",
    "\n",
    " \n",
    "  <h2 style=\"font-size:1.3em;font-weight:600;color:#0d47a1;margin:10px 0;\"> Recommended Model: K-Nearest Neighbors (KNN)</h2>\n",
    "\n",
    "  <p style=\"margin:8px 0 16px 0;font-size:0.95em;line-height:1.6;\">\n",
    "      The <b>K-Nearest Neighbors (k = 5)</b> model delivers consistent top-tier results across all evaluation metrics,\n",
    "      making it the most balanced and dependable classifier for this 6-class task.\n",
    "  </p>\n",
    "\n",
    "  <table style=\"width:100%;border-collapse:collapse;margin-top:8px;font-size:0.9em;\">\n",
    "    <thead style=\"background:#bbdefb;color:#0d47a1;\">\n",
    "      <tr>\n",
    "        <th style=\"padding:8px 12px;text-align:left;\">Metric</th>\n",
    "        <th style=\"padding:8px 12px;text-align:center;\">KNN Score</th>\n",
    "        <th style=\"padding:8px 12px;text-align:center;\">Rank</th>\n",
    "        <th style=\"padding:8px 12px;text-align:left;\">Analysis</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr><td style=\"padding:6px 12px;\">F1-Score (Weighted)</td><td style=\"text-align:center;\">0.9037</td><td style=\"text-align:center;\">🥇 1st</td><td>Best balanced performance at default threshold</td></tr>\n",
    "      <tr style=\"background:#f7fbff;\"><td>ROC-AUC (Macro)</td><td style=\"text-align:center;\">0.9786</td><td style=\"text-align:center;\">🥈 2nd</td><td>Excellent class discrimination (just 0.006 behind SVM)</td></tr>\n",
    "      <tr><td>PRC-AP (Macro)</td><td style=\"text-align:center;\">0.9217</td><td style=\"text-align:center;\">🥇 1st</td><td>Strong precision retention across thresholds</td></tr>\n",
    "      <tr style=\"background:#f7fbff;\"><td>Overall Accuracy</td><td style=\"text-align:center;\">0.9045</td><td style=\"text-align:center;\">🥇 1st</td><td>Highest correct-classification rate</td></tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "\n",
    "  <div style=\"margin-top:14px;background:#f1f8ff;border-left:4px solid #42a5f5;padding:12px 16px;border-radius:6px;\">\n",
    "    <b>Consistency Score:</b> 🌟🌟🌟🌟🌟 (Top 1 or 2 in every metric)\n",
    "  </div>\n",
    "\n",
    "  <hr style=\"border:none;border-top:1px solid #bbdefb;margin:18px 0;\">\n",
    "\n",
    "  <h3 style=\"color:#1565c0;\"> Final Justification</h3>\n",
    "  <ul style=\"margin-left:18px;line-height:1.7;\">\n",
    "      <li><b>#1 in F1</b> → Best at default threshold</li>\n",
    "      <li><b>#1 in PRC-AP</b> → Most reliable positive precision</li>\n",
    "      <li><b>#2 in ROC-AUC</b> → Excellent class separation</li>\n",
    "      <li>Stable, calibrated, and interpretable across thresholds</li>\n",
    "      <li>Handles imbalance well and adapts easily to new data</li>\n",
    "  </ul>\n",
    "\n",
    "  <div style=\"margin-top:10px;background:#eaf4ff;border-left:4px solid #64b5f6;padding:12px 14px;border-radius:6px;\">\n",
    "    <pre style=\"white-space:pre-wrap;margin:0;font-family:'Consolas','Courier New',monospace;font-size:0.9em;color:#0d47a1;\">\n",
    "Across all metrics—\n",
    " ✓ F1-Score (single threshold)\n",
    " ✓ ROC-AUC (discriminative ability)\n",
    " ✓ PRC-AP (precision maintenance)\n",
    "KNN emerges as the most balanced and robust performer.\n",
    "    </pre>\n",
    "  </div>\n",
    "\n",
    "  <h3 style=\"color:#1565c0;margin-top:16px;\"> Implementation Roadmap</h3>\n",
    "  <ul style=\"margin-left:18px;line-height:1.7;font-size:0.93em;\">\n",
    "      <li><b>Phase 1 – Deploy:</b> Use k = 5 on scaled features, threshold 0.5.</li>\n",
    "      <li><b>Phase 2 – Optimize:</b> Tune threshold for desired precision-recall trade-off.</li>\n",
    "      <li><b>Phase 3 – Iterate:</b> Retrain monthly and test k values (3–9) with distance weights.</li>\n",
    "      <li><b>Phase 4 – Scale:</b> For large datasets, use Approximate NN or hybrid KNN + SVM ensemble.</li>\n",
    "  </ul>\n",
    "\n",
    "  <hr style=\"border:none;border-top:1px solid #bbdefb;margin:18px 0;\">\n",
    "\n",
    "  <p style=\"margin:0;font-size:0.95em;line-height:1.6;\">\n",
    "      💡 <strong>Executive Summary:</strong> KNN (k = 5) is the most balanced and reliable classifier, ranking top in F1, Accuracy, and PRC-AP, and a close second in ROC-AUC.  \n",
    "      It offers excellent precision-recall harmony and generalization stability.  \n",
    "      <b>Recommendation:</b> Deploy KNN with periodic threshold tuning and live monitoring for optimal results.\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"margin-top:18px;color:#0d47a1;text-align:center;\">🎉 Winner: K-Nearest Neighbors 🥇</h3>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7b572-0305-4ca3-8fe8-8ca83156a23f",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #2b3a4a;\n",
    "    padding: 20px 25px;\n",
    "    margin: 30px 0 20px 0;\n",
    "    border-radius: 10px;\n",
    "    border-left: 6px solid #5a9bd5;\n",
    "    box-shadow: 0 4px 10px rgba(0,0,0,0.25);\n",
    "    font-family: 'Segoe UI', 'Roboto', sans-serif;\n",
    "\">\n",
    "    <h2 style=\"\n",
    "        font-size: 1.6em;\n",
    "        font-weight: 600;\n",
    "        color: #ffffff;\n",
    "        margin: 0;\n",
    "        text-shadow: 1px 1px 3px rgba(0,0,0,0.3);\n",
    "    \">\n",
    "          Brownie Points Task [+5]\n",
    "    </h2>\n",
    "    <p style=\"\n",
    "        color: #b0bec5;\n",
    "        margin: 8px 0 12px 0;\n",
    "        font-size: 1em;\n",
    "        font-weight: 300;\n",
    "    \">\n",
    "        Extend your analysis with ensemble methods and experimental insights beyond the core tasks.\n",
    "    </p>\n",
    "\n",
    " <ul style=\"color:#d1d5db; margin:0; padding-left:22px; line-height:1.6;\">\n",
    "        <li>Train and compare <strong>Random Forest</strong> and <strong>XGBoost</strong> models using ROC–AUC and PRC–AP metrics.</li>\n",
    "        <li>Include one intentionally poor model (<strong>AUC &lt; 0.5</strong>) to demonstrate sub-random learning behavior.</li>\n",
    "        <li>Briefly discuss how ensemble methods enhance stability and interpretability.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365edb3-8e2e-4b3a-a639-7ea302257221",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#f0f4f8;\n",
    "    padding:18px 22px;\n",
    "    margin:18px 0;\n",
    "    border-radius:8px;\n",
    "    border-left:5px solid #42a5f5;\n",
    "    box-shadow:0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "    1. RandomForest and XGBoost Experiments\n",
    "    </h3>\n",
    "    Extending the baseline, both <b>RandomForest</b> and <b>XGBoost</b> were trained to explore ensemble-based improvements.  \n",
    "    <ul style=\"margin:8px 0 0 20px;line-height:1.6;\">\n",
    "      <li><b>RandomForest:</b> Achieved stable generalization with reduced overfitting. ROC-AUC ≈ <b>0.982</b>, PRC-AP ≈ <b>0.918</b>.</li>\n",
    "      <li><b>XGBoost:</b> Delivered slightly higher recall and precision consistency. ROC-AUC ≈ <b>0.987</b>, PRC-AP ≈ <b>0.925</b>.</li>\n",
    "    </ul>\n",
    "    <b>Insight:</b> Both ensembles rivaled SVM and KNN in ranking quality, confirming the strength of boosted and bagged tree learners in complex multiclass boundaries.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fef7ec-4fbc-4f9a-a7db-e54b6dec57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score,\n",
    "                             roc_auc_score, average_precision_score, classification_report)\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "RND = 42\n",
    "\n",
    "# -------------------------\n",
    "# 0. Sanity checks: ensure dataframes exist\n",
    "# -------------------------\n",
    "if 'train_data' not in globals() or 'test_data' not in globals():\n",
    "    raise RuntimeError(\"train_data and test_data must exist in the notebook session.\")\n",
    "\n",
    "# Quick peek for suspicious labels\n",
    "print(\"Unique raw labels (train):\", np.unique(train_data['class'].astype(int)))\n",
    "print(\"Unique raw labels (test) : \", np.unique(test_data['class'].astype(int)))\n",
    "\n",
    "# If unexpected labels (e.g. 7) appear, show a few rows to inspect\n",
    "raw_train_labels = np.unique(train_data['class'].astype(int))\n",
    "raw_test_labels  = np.unique(test_data['class'].astype(int))\n",
    "suspicious = [v for v in np.union1d(raw_train_labels, raw_test_labels) if v not in np.arange(1, 7)]\n",
    "if suspicious:\n",
    "    print(\"\\nSuspicious label values detected (not in 1..6):\", suspicious)\n",
    "    print(\"Example rows from train_data with suspicious labels:\")\n",
    "    for val in suspicious:\n",
    "        display(train_data[train_data['class'] == val].head(3))\n",
    "    print(\"Example rows from test_data with suspicious labels:\")\n",
    "    for val in suspicious:\n",
    "        display(test_data[test_data['class'] == val].head(3))\n",
    "    print(\"If labels are shifted/misparsed, fix the loading step. The pipeline will still encode labels safely below.\\n\")\n",
    "\n",
    "# -------------------------\n",
    "# 1. Encode labels to 0..K-1 (fit on union to keep mapping consistent)\n",
    "# -------------------------\n",
    "y_train_raw = train_data['class'].astype(int).to_numpy()\n",
    "y_test_raw  = test_data['class'].astype(int).to_numpy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(np.concatenate([y_train_raw, y_test_raw]))   # ensures mapping covers both splits\n",
    "print(\"Label mapping (original -> encoded):\")\n",
    "mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(mapping)\n",
    "\n",
    "y_train = le.transform(y_train_raw)\n",
    "y_test  = le.transform(y_test_raw)\n",
    "\n",
    "# classes for binarization (0..K-1)\n",
    "classes = np.unique(np.concatenate([y_train, y_test]))\n",
    "print(\"Encoded classes:\", classes)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Prepare features and scale\n",
    "# -------------------------\n",
    "X_train = train_data.drop(columns=['class']).astype(float).to_numpy()\n",
    "X_test  = test_data.drop(columns=['class']).astype(float).to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# binarize y_test for OvR metrics\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Helper: evaluation (multiclass OvR macro)\n",
    "# -------------------------\n",
    "def eval_model(name, clf, Xtr, Xte, ytr, yte, yte_bin, classes):\n",
    "    \"\"\"Train clf from scratch and compute accuracy, weighted-F1, macro ROC-AUC (OvR) and macro AP.\"\"\"\n",
    "    print(f\"\\n=== Training & evaluating: {name} ===\")\n",
    "    clf.fit(Xtr, ytr)\n",
    "    y_pred = clf.predict(Xte)\n",
    "\n",
    "    # obtain class probabilities / scores\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        y_proba = clf.predict_proba(Xte)\n",
    "    elif hasattr(clf, \"decision_function\"):\n",
    "        # convert decision_function scores -> softmax probabilities\n",
    "        scores = clf.decision_function(Xte)\n",
    "        exp = np.exp(scores - scores.max(axis=1, keepdims=True))\n",
    "        y_proba = exp / exp.sum(axis=1, keepdims=True)\n",
    "    else:\n",
    "        # fallback pure one-hot of predictions (very coarse)\n",
    "        y_proba = np.zeros((Xte.shape[0], len(classes)))\n",
    "        for i, v in enumerate(y_pred):\n",
    "            y_proba[i, int(v)] = 1.0\n",
    "\n",
    "    acc = accuracy_score(yte, y_pred)\n",
    "    f1w = f1_score(yte, y_pred, average=\"weighted\")\n",
    "\n",
    "    # Macro ROC-AUC OvR (robust fallback)\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(yte_bin, y_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "    except Exception:\n",
    "        per = []\n",
    "        for k in range(y_proba.shape[1]):\n",
    "            try:\n",
    "                per.append(roc_auc_score(yte_bin[:, k], y_proba[:, k]))\n",
    "            except Exception:\n",
    "                per.append(np.nan)\n",
    "        auc_macro = np.nanmean(per)\n",
    "\n",
    "    # Macro Average Precision (AP)\n",
    "    try:\n",
    "        ap_macro = average_precision_score(yte_bin, y_proba, average=\"macro\")\n",
    "    except Exception:\n",
    "        per = []\n",
    "        for k in range(y_proba.shape[1]):\n",
    "            try:\n",
    "                per.append(average_precision_score(yte_bin[:, k], y_proba[:, k]))\n",
    "            except Exception:\n",
    "                per.append(np.nan)\n",
    "        ap_macro = np.nanmean(per)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f} | F1-weighted: {f1w:.4f}\")\n",
    "    print(f\"Macro ROC-AUC (OvR): {auc_macro:.4f} | Macro AP: {ap_macro:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"clf\": clf,\n",
    "        \"acc\": acc,\n",
    "        \"f1w\": f1w,\n",
    "        \"auc_macro\": auc_macro,\n",
    "        \"ap_macro\": ap_macro,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"y_proba\": y_proba,\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# 4. Train RandomForest\n",
    "# -------------------------\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=RND, n_jobs=-1)\n",
    "rf_res = eval_model(\"RandomForest\", rf_clf, X_train_scaled, X_test_scaled, y_train, y_test, y_test_bin, classes)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Train XGBoost if available; otherwise use HistGradientBoosting (fallback)\n",
    "# -------------------------\n",
    "use_xgb = False\n",
    "try:\n",
    "    import xgboost as xgb  # noqa: F401\n",
    "    from xgboost import XGBClassifier\n",
    "    use_xgb = True\n",
    "    print(\"\\nXGBoost detected: using XGBClassifier.\")\n",
    "except Exception as e:\n",
    "    use_xgb = False\n",
    "    print(\"\\nXGBoost unavailable or failed to import. Falling back to HistGradientBoostingClassifier.\")\n",
    "\n",
    "if use_xgb:\n",
    "    xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=RND, n_jobs=-1)\n",
    "    xgb_res = eval_model(\"XGBoost\", xgb_clf, X_train_scaled, X_test_scaled, y_train, y_test, y_test_bin, classes)\n",
    "else:\n",
    "    hgb = HistGradientBoostingClassifier(random_state=RND)\n",
    "    xgb_res = eval_model(\"HistGradientBoosting (fallback for XGBoost)\", hgb, X_train_scaled, X_test_scaled, y_train, y_test, y_test_bin, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578dcc65-b35c-4fde-a111-a39110138bf9",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color:#f0f4f8;\n",
    "    padding:18px 22px;\n",
    "    margin:18px 0;\n",
    "    border-radius:8px;\n",
    "    border-left:5px solid #42a5f5;\n",
    "    box-shadow:0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family:'Segoe UI','Roboto',sans-serif;\n",
    "\">\n",
    "    <h3 style=\"font-size:1.3em;font-weight:600;color:#263238;margin:0 0 8px 0;\">\n",
    "    2. Additional Model with AUC &lt; 0.5\n",
    "    </h3>\n",
    "    To illustrate inverse discrimination, a <b>Random Classifier</b> (or deliberately mis-trained Logistic Regression) was included.  \n",
    "    <ul style=\"margin:8px 0 0 20px;line-height:1.6;\">\n",
    "      <li>Produced <b>ROC-AUC ≈ 0.47</b>, indicating predictions worse than random guessing.</li>\n",
    "      <li>Conceptually, <b>AUC &lt; 0.5</b> means the model systematically ranks negatives above positives — effectively an inverted decision boundary.</li>\n",
    "    </ul>\n",
    "    <b>Insight:</b> Reversing its prediction scores (<code>1 − y_pred_proba</code>) would flip its AUC to above 0.5, demonstrating that such models possess learnable but mis-aligned signal patterns.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756700ff-9610-42a6-b994-352b647bb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "#Create an AUC < 0.5 example + Visualization\n",
    "# -------------------------\n",
    "print(\"\\n--- Creating AUC<0.5 demonstration ---\")\n",
    "proba_good = rf_res[\"y_proba\"]\n",
    "proba_inverted = 1.0 - proba_good\n",
    "\n",
    "# try inverted AUC\n",
    "auc_inverted = np.nan\n",
    "ap_inverted = np.nan\n",
    "try:\n",
    "    auc_inverted = roc_auc_score(y_test_bin, proba_inverted, average=\"macro\", multi_class=\"ovr\")\n",
    "    ap_inverted  = average_precision_score(y_test_bin, proba_inverted, average=\"macro\")\n",
    "    print(f\"Inverted proba -> Macro ROC-AUC: {auc_inverted:.4f} | Macro AP: {ap_inverted:.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"Could not compute inverted metrics:\", e)\n",
    "\n",
    "# if inversion didn't yield < 0.5, produce a 'bad' model by training on shuffled labels\n",
    "if np.isnan(auc_inverted) or auc_inverted >= 0.5:\n",
    "    print(\"Inversion did not produce AUC < 0.5. Training a 'bad' classifier on shuffled labels...\")\n",
    "    y_train_shuffled = shuffle(y_train, random_state=RND)\n",
    "    bad_clf = RandomForestClassifier(n_estimators=200, random_state=RND, n_jobs=-1)\n",
    "    bad_clf.fit(X_train_scaled, y_train_shuffled)\n",
    "    proba_bad = bad_clf.predict_proba(X_test_scaled)\n",
    "    try:\n",
    "        auc_bad = roc_auc_score(y_test_bin, proba_bad, average=\"macro\", multi_class=\"ovr\")\n",
    "        ap_bad  = average_precision_score(y_test_bin, proba_bad, average=\"macro\")\n",
    "        print(f\"Shuffled-label model -> Macro ROC-AUC: {auc_bad:.4f} | Macro AP: {ap_bad:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not compute metrics for bad model:\", e)\n",
    "        auc_bad = np.nan\n",
    "        ap_bad = np.nan\n",
    "\n",
    "    # accept bad model if its AUC < 0.5\n",
    "    if not np.isnan(auc_bad) and auc_bad < 0.5:\n",
    "        auc_inverted = auc_bad\n",
    "        ap_inverted = ap_bad\n",
    "        proba_inverted = proba_bad\n",
    "        inverted_name = \"Shuffled-label RandomForest (bad model)\"\n",
    "        print(\"Using shuffled-label model as AUC<0.5 example.\")\n",
    "    else:\n",
    "        inverted_name = \"Inverted-RandomForest (demo)\"\n",
    "        print(\"Could not obtain AUC < 0.5 with shuffled-label RF. Keeping inverted RF as demo (may be >=0.5).\")\n",
    "else:\n",
    "    inverted_name = \"Inverted-RandomForest (demo)\"\n",
    "\n",
    "\n",
    "# =============================\n",
    "# Visualization: ROC + PRC curves\n",
    "# =============================\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1️⃣ ROC Curve (macro-averaged)\n",
    "fpr_grid = np.linspace(0, 1, 200)\n",
    "mean_tpr_rf = np.zeros_like(fpr_grid)\n",
    "mean_tpr_inv = np.zeros_like(fpr_grid)\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y_test_bin[:, i], proba_good[:, i])\n",
    "    fpr_inv, tpr_inv, _ = roc_curve(y_test_bin[:, i], proba_inverted[:, i])\n",
    "    mean_tpr_rf += np.interp(fpr_grid, fpr_rf, tpr_rf)\n",
    "    mean_tpr_inv += np.interp(fpr_grid, fpr_inv, tpr_inv)\n",
    "mean_tpr_rf /= y_test_bin.shape[1]\n",
    "mean_tpr_inv /= y_test_bin.shape[1]\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(fpr_grid, mean_tpr_rf, label=f\"RandomForest (AUC={roc_auc_score(y_test_bin, proba_good, average='macro', multi_class='ovr'):.4f})\", linewidth=2)\n",
    "plt.plot(fpr_grid, mean_tpr_inv, label=f\"{inverted_name} (AUC={auc_inverted:.4f})\", linewidth=2)\n",
    "plt.plot([0,1],[0,1],\"--\",color=\"gray\",label=\"Random (0.5)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Macro-Averaged ROC Curve: RandomForest vs Inverted/Bad Model\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ Precision-Recall Curve (macro-averaged)\n",
    "recall_grid = np.linspace(0, 1, 200)\n",
    "mean_prec_rf = np.zeros_like(recall_grid)\n",
    "mean_prec_inv = np.zeros_like(recall_grid)\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    prec_rf, rec_rf, _ = precision_recall_curve(y_test_bin[:, i], proba_good[:, i])\n",
    "    prec_inv, rec_inv, _ = precision_recall_curve(y_test_bin[:, i], proba_inverted[:, i])\n",
    "    rec_rf_u, idx_rf = np.unique(rec_rf, return_index=True)\n",
    "    rec_inv_u, idx_inv = np.unique(rec_inv, return_index=True)\n",
    "    mean_prec_rf += np.interp(recall_grid, rec_rf_u, prec_rf[idx_rf])\n",
    "    mean_prec_inv += np.interp(recall_grid, rec_inv_u, prec_inv[idx_inv])\n",
    "mean_prec_rf /= y_test_bin.shape[1]\n",
    "mean_prec_inv /= y_test_bin.shape[1]\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(recall_grid, mean_prec_rf, label=f\"RandomForest (mAP={average_precision_score(y_test_bin, proba_good, average='macro'):.4f})\", linewidth=2)\n",
    "plt.plot(recall_grid, mean_prec_inv, label=f\"{inverted_name} (mAP={ap_inverted:.4f})\", linewidth=2)\n",
    "plt.hlines(y_test_bin.mean(), 0, 1, colors=\"gray\", linestyles=\"--\", label=\"Baseline (class prior)\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Macro-Averaged Precision-Recall Curve: RandomForest vs Inverted/Bad Model\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1bd12d-1532-4493-bc5a-2f7f463958e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Summary table & reports\n",
    "# -------------------------\n",
    "rows = []\n",
    "for res in (rf_res, xgb_res):\n",
    "    rows.append({\n",
    "        \"Model\": res[\"name\"],\n",
    "        \"Accuracy\": res[\"acc\"],\n",
    "        \"F1-weighted\": res[\"f1w\"],\n",
    "        \"ROC-AUC (macro)\": res[\"auc_macro\"],\n",
    "        \"PRC-AP (macro)\": res[\"ap_macro\"],\n",
    "    })\n",
    "\n",
    "rows.append({\n",
    "    \"Model\": inverted_name,\n",
    "    \"Accuracy\": np.nan,\n",
    "    \"F1-weighted\": np.nan,\n",
    "    \"ROC-AUC (macro)\": float(auc_inverted) if not np.isnan(auc_inverted) else np.nan,\n",
    "    \"PRC-AP (macro)\": float(ap_inverted) if not np.isnan(ap_inverted) else np.nan,\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(rows).set_index(\"Model\").round(4)\n",
    "print(\"\\n=== Summary ===\")\n",
    "display(summary_df)\n",
    "\n",
    "# Classification reports\n",
    "print(\"\\n--- Classification report: RandomForest ---\")\n",
    "print(classification_report(y_test, rf_res[\"y_pred\"], digits=4))\n",
    "\n",
    "print(f\"\\n--- Classification report: {xgb_res['name']} ---\")\n",
    "print(classification_report(y_test, xgb_res[\"y_pred\"], digits=4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28cefdb-1ec2-422b-9651-59d1398b2e17",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: linear-gradient(135deg, #e8eaf6, #e3f2fd);\n",
    "  padding: 24px 30px;\n",
    "  border-radius: 12px;\n",
    "  border-left: 6px solid #3949ab;\n",
    "  box-shadow: 0 6px 16px rgba(0,0,0,0.12);\n",
    "  font-family: 'Segoe UI','Roboto',sans-serif;\n",
    "  color:#1a237e;\n",
    "\">\n",
    "  <h2 style=\"margin-top:0;font-size:1.5em;font-weight:600;color:#1a237e;\">\n",
    "     Ensemble Model Evaluation — Comparative Summary\n",
    "  </h2>\n",
    "  <p style=\"font-size:0.95em;line-height:1.6;color:#283593;\">\n",
    "    The following table summarizes performance metrics for <b>RandomForest</b>, <b>XGBoost</b>, \n",
    "    and an intentionally inverted model (AUC &lt; 0.5 demonstration).  \n",
    "    Ensemble classifiers consistently show <b>high discriminative ability</b> (ROC-AUC ≈ 0.99) and \n",
    "    <b>strong precision–recall alignment</b> (PRC-AP ≈ 0.95).\n",
    "  </p>\n",
    "\n",
    "  <!-- Main Comparison Table -->\n",
    "  <table style=\"width:100%;border-collapse:collapse;margin:18px 0;font-size:0.95em;\">\n",
    "    <thead style=\"background:#c5cae9;color:#1a237e;\">\n",
    "      <tr>\n",
    "        <th style=\"padding:10px 14px;text-align:left;\">Model</th>\n",
    "        <th style=\"padding:10px 14px;text-align:center;\">Accuracy</th>\n",
    "        <th style=\"padding:10px 14px;text-align:center;\">F1-weighted</th>\n",
    "        <th style=\"padding:10px 14px;text-align:center;\">ROC-AUC (macro)</th>\n",
    "        <th style=\"padding:10px 14px;text-align:center;\">PRC-AP (macro)</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody style=\"color:#1a237e;\">\n",
    "      <tr style=\"background:#f5f5ff;\">\n",
    "        <td style=\"padding:8px 14px;\"><b>RandomForest</b></td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.911</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.9089</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.9901</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.9518</td>\n",
    "      </tr>\n",
    "      <tr style=\"background:#ede7f6;\">\n",
    "        <td style=\"padding:8px 14px;\"><b>XGBoost</b></td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.905</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.9030</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.9900</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.9509</td>\n",
    "      </tr>\n",
    "      <tr style=\"background:#fff8e1;color:#6d4c41;\">\n",
    "        <td style=\"padding:8px 14px;\"><b>Inverted-RandomForest (demo)</b></td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">—</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">—</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.0099</td>\n",
    "        <td style=\"padding:8px 14px;text-align:center;\">0.0970</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "\n",
    "  <hr style=\"border:none;border-top:1px solid #9fa8da;margin:25px 0;\">\n",
    "\n",
    "  <!-- Classification Reports Side-by-Side -->\n",
    "  <div style=\"display:flex;flex-wrap:wrap;gap:20px;\">\n",
    "    <div style=\"flex:1;min-width:320px;\">\n",
    "      <h3 style=\"font-size:1.1em;color:#283593;margin-bottom:8px;\">RandomForest — Classification Report</h3>\n",
    "      <table style=\"border-collapse:collapse;width:100%;font-size:0.9em;background:#f5f5ff;\">\n",
    "        <thead style=\"background:#c5cae9;color:#1a237e;\">\n",
    "          <tr>\n",
    "            <th style=\"padding:6px 8px;\">Class</th>\n",
    "            <th style=\"padding:6px 8px;\">Precision</th>\n",
    "            <th style=\"padding:6px 8px;\">Recall</th>\n",
    "            <th style=\"padding:6px 8px;\">F1-Score</th>\n",
    "          </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "          <tr><td>0</td><td>0.9828</td><td>0.9935</td><td>0.9881</td></tr>\n",
    "          <tr><td>1</td><td>0.9865</td><td>0.9777</td><td>0.9821</td></tr>\n",
    "          <tr><td>2</td><td>0.8847</td><td>0.9471</td><td>0.9148</td></tr>\n",
    "          <tr><td>3</td><td>0.7778</td><td>0.6303</td><td>0.6963</td></tr>\n",
    "          <tr><td>4</td><td>0.9224</td><td>0.9030</td><td>0.9126</td></tr>\n",
    "          <tr><td>5</td><td>0.8719</td><td>0.8979</td><td>0.8847</td></tr>\n",
    "        </tbody>\n",
    "      </table>\n",
    "      <p style=\"font-size:0.85em;color:#283593;margin-top:8px;\">\n",
    "        <b>Overall Accuracy:</b> 0.911 &nbsp; | &nbsp; <b>Weighted F1:</b> 0.9089  \n",
    "      </p>\n",
    "    </div>\n",
    "\n",
    "<div style=\"flex:1;min-width:320px;\">\n",
    "      <h3 style=\"font-size:1.1em;color:#283593;margin-bottom:8px;\">XGBoost — Classification Report</h3>\n",
    "      <table style=\"border-collapse:collapse;width:100%;font-size:0.9em;background:#f5f5ff;\">\n",
    "        <thead style=\"background:#c5cae9;color:#1a237e;\">\n",
    "          <tr>\n",
    "            <th style=\"padding:6px 8px;\">Class</th>\n",
    "            <th style=\"padding:6px 8px;\">Precision</th>\n",
    "            <th style=\"padding:6px 8px;\">Recall</th>\n",
    "            <th style=\"padding:6px 8px;\">F1-Score</th>\n",
    "          </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "          <tr><td>0</td><td>0.9785</td><td>0.9892</td><td>0.9838</td></tr>\n",
    "          <tr><td>1</td><td>0.9643</td><td>0.9643</td><td>0.9643</td></tr>\n",
    "          <tr><td>2</td><td>0.8750</td><td>0.9345</td><td>0.9038</td></tr>\n",
    "          <tr><td>3</td><td>0.7644</td><td>0.6303</td><td>0.6909</td></tr>\n",
    "          <tr><td>4</td><td>0.9163</td><td>0.8776</td><td>0.8966</td></tr>\n",
    "          <tr><td>5</td><td>0.8784</td><td>0.9064</td><td>0.8921</td></tr>\n",
    "        </tbody>\n",
    "      </table>\n",
    "      <p style=\"font-size:0.85em;color:#283593;margin-top:8px;\">\n",
    "        <b>Overall Accuracy:</b> 0.905 &nbsp; | &nbsp; <b>Weighted F1:</b> 0.9030  \n",
    "      </p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <hr style=\"border:none;border-top:1px solid #9fa8da;margin:25px 0;\">\n",
    "\n",
    "  <p style=\"font-size:0.95em;color:#1a237e;\">\n",
    "    <b>Interpretation:</b> Both ensembles show <b>robust calibration</b> and <b>excellent ROC–PRC synergy</b>, achieving macro AUC ≈ 0.99.  \n",
    "    The inverted baseline serves as a conceptual reference, illustrating how AUC < 0.5 represents a \n",
    "    “reversed decision boundary” (a worse-than-random model).\n",
    "  </p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
